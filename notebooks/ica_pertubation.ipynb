{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tedana.cli import run\n",
    "import pandas as pd\n",
    "from numba import jit\n",
    "from scipy.linalg import expm\n",
    "from time import gmtime, strftime\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn\n",
    "%matplotlib inline\n",
    "%load_ext line_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import gzip\n",
    "import pickle\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "from sklearn import svm\n",
    "import scipy.stats as stats\n",
    "from tedana.interfaces.t2smap import (optcom, t2sadmap)\n",
    "from tedana.utils.utils import (cat2echos, uncat2echos, make_mask,\n",
    "                                makeadmask, fmask, unmask,\n",
    "                                fitgaussian, niwrite, dice, andb)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "PROCEDURE 2 : Computes ME-PCA and ME-ICA\n",
    "-Computes T2* map\n",
    "-Computes PCA of concatenated ME data, then computes TE-dependence of PCs\n",
    "-Computes ICA of TE-dependence PCs\n",
    "-Identifies TE-dependent ICs, outputs high-\\kappa (BOLD) component\n",
    "   and denoised time series\n",
    "-or- Computes TE-dependence of each component of a general linear model\n",
    "   specified by input (includes MELODIC FastICA mixing matrix)\n",
    "PROCEDURE 2a: Model fitting and component selection routines\n",
    "\"\"\"\n",
    "\n",
    "F_MAX = 500\n",
    "Z_MAX = 8\n",
    "\n",
    "\n",
    "def do_svm(X_train, y_train, X_test, svmtype=0):\n",
    "    \"\"\"\n",
    "    sklearn's Support Vector Classification (SVC).\n",
    "    For svmtype=1, implemented in liblinear rather than libsvm.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X_train : {array-like, sparse matrix}, shape (n_samples, n_features)\n",
    "        Training vectors, where n_samples is the number of samples in the\n",
    "        training dataset and n_features is the number of features.\n",
    "    y_train : array-like, shape (n_samples,)\n",
    "        Target values (class labels in classification, real numbers in\n",
    "        regression)\n",
    "    X_test : {array-like, sparse matrix}, shape (n_samples, n_features)\n",
    "        Test vectors, where n_samples is the number of samples in the test\n",
    "        dataset and n_features is the number of features.\n",
    "    svmtype : int\n",
    "        Desired support vector machine type.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    y_pred : array, shape (n_samples,)\n",
    "        Predicted class labels for samples in X_test.\n",
    "    clf : {:obj:`sklearn.svm.classes.SVC`, :obj:`sklearn.svm.classes.LinearSVC`}\n",
    "        Trained sklearn model instance.\n",
    "    \"\"\"\n",
    "\n",
    "    if svmtype == 0:\n",
    "        clf = svm.SVC(kernel='linear')\n",
    "    elif svmtype == 1:\n",
    "        clf = svm.LinearSVC(loss='squared_hinge', penalty='l1', dual=False)\n",
    "    elif svmtype == 2:\n",
    "        clf = svm.SVC(kernel='linear', probability=True)\n",
    "    else:\n",
    "        raise ValueError('Input svmtype not in range (3)')\n",
    "\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    return y_pred, clf\n",
    "\n",
    "\n",
    "def spatclust(data, mask, csize, thr, header, aff, infile=None, dindex=0,\n",
    "              tindex=0):\n",
    "    \"\"\"\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data :\n",
    "\n",
    "    mask :\n",
    "\n",
    "    csize :\n",
    "\n",
    "    thr :\n",
    "\n",
    "    header :\n",
    "\n",
    "    aff :\n",
    "\n",
    "    infile :\n",
    "\n",
    "    dindex :\n",
    "\n",
    "    tindex :\n",
    "\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    clustered :\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    if infile is None:\n",
    "        data = data.copy()\n",
    "        data[data < thr] = 0\n",
    "        niwrite(unmask(data, mask), aff, '__clin.nii.gz', header)\n",
    "        infile = '__clin.nii.gz'\n",
    "    addopts = ''\n",
    "    if data is not None and len(np.squeeze(data).shape) > 1 and dindex + tindex == 0:\n",
    "        addopts = '-doall'\n",
    "    else:\n",
    "        addopts = '-1dindex {0} -1tindex {1}'.format(str(dindex), str(tindex))\n",
    "\n",
    "    cmd_str = '3dmerge -overwrite {0} -dxyz=1  -1clust 1 {1:d} -1thresh {2:.02f} -prefix __clout.nii.gz {3}'\n",
    "    os.system(cmd_str.format(addopts, int(csize), float(thr), infile))\n",
    "    clustered = fmask(nib.load('__clout.nii.gz').get_data(), mask) != 0\n",
    "    return clustered\n",
    "\n",
    "\n",
    "def rankvec(vals):\n",
    "    \"\"\"Returns ranks of array.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    vals : array-like\n",
    "        1d array from which to determine ranks.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    ranks : array-like\n",
    "        1d array of ranks for values in input vals.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        vals = np.array(vals)\n",
    "    except:\n",
    "        raise IOError('Input vals is not array_like')\n",
    "\n",
    "    if len(vals.shape) != 1:\n",
    "        raise ValueError('Input vals is not 1d array')\n",
    "\n",
    "    asort = np.argsort(vals)\n",
    "    ranks = np.zeros(vals.shape[0])\n",
    "    ranks[asort] = np.arange(vals.shape[0]) + 1\n",
    "    return ranks\n",
    "\n",
    "\n",
    "def get_coeffs(data, mask, X, add_const=False):\n",
    "    \"\"\"\n",
    "    get_coeffs(data,X)\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : array-like\n",
    "        Array of shape (nx, ny, nz, nt)\n",
    "    mask : array-like\n",
    "        Array of shape (nx, ny, nz)\n",
    "    X : array-like\n",
    "        Array of shape (nt, nc)\n",
    "    add_const : bool, optional\n",
    "        Default is False.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    out : array_like\n",
    "        Array of shape (nx, ny, nz, nc)\n",
    "    \"\"\"\n",
    "    mdata = fmask(data, mask).transpose()\n",
    "\n",
    "    # Coerce X to >=2d\n",
    "    X = np.atleast_2d(X)\n",
    "\n",
    "    if X.shape[0] == 1:\n",
    "        X = X.T\n",
    "    Xones = np.atleast_2d(np.ones(np.min(mdata.shape))).T\n",
    "    if add_const:\n",
    "        X = np.hstack([X, Xones])\n",
    "\n",
    "    tmpbetas = np.linalg.lstsq(X, mdata)[0].transpose()\n",
    "    if add_const:\n",
    "        tmpbetas = tmpbetas[:, :-1]\n",
    "    out = unmask(tmpbetas, mask)\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "def getelbow_cons(ks, val=False):\n",
    "    \"\"\"Elbow using mean/variance method - conservative\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    ks : array-like\n",
    "\n",
    "    val : bool, optional\n",
    "        Default is False\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    array-like\n",
    "        Either the elbow index (if val is True) or the values at the elbow\n",
    "        index (if val is False)\n",
    "    \"\"\"\n",
    "    ks = np.sort(ks)[::-1]\n",
    "    nk = len(ks)\n",
    "    temp1 = [(ks[nk-5-ii-1] > ks[nk-5-ii:nk].mean() + 2*ks[nk-5-ii:nk].std()) for ii in range(nk-5)]\n",
    "    ds = np.array(temp1[::-1], dtype=np.int)\n",
    "    dsum = []\n",
    "    c_ = 0\n",
    "    for d_ in ds:\n",
    "        c_ = (c_ + d_) * d_\n",
    "        dsum.append(c_)\n",
    "    e2 = np.argmax(np.array(dsum))\n",
    "    elind = np.max([getelbow_mod(ks), e2])\n",
    "\n",
    "    if val: return ks[elind]\n",
    "    else: return elind\n",
    "\n",
    "\n",
    "def getelbow_mod(ks, val=False):\n",
    "    \"\"\"Elbow using linear projection method - moderate\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    ks : array-like\n",
    "\n",
    "    val : bool, optional\n",
    "        Default is False\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    array-like\n",
    "        Either the elbow index (if val is True) or the values at the elbow\n",
    "        index (if val is False)\n",
    "    \"\"\"\n",
    "    ks = np.sort(ks)[::-1]\n",
    "    nc = ks.shape[0]\n",
    "    coords = np.array([np.arange(nc), ks])\n",
    "    p  = coords - np.tile(np.reshape(coords[:, 0], (2, 1)), (1, nc))\n",
    "    b  = p[:, -1]\n",
    "    b_hat = np.reshape(b / np.sqrt((b ** 2).sum()), (2, 1))\n",
    "    proj_p_b = p - np.dot(b_hat.T, p) * np.tile(b_hat, (1, nc))\n",
    "    d = np.sqrt((proj_p_b ** 2).sum(axis=0))\n",
    "    k_min_ind = d.argmax()\n",
    "    k_min  = ks[k_min_ind]\n",
    "\n",
    "    if val: return ks[k_min_ind]\n",
    "    else: return k_min_ind\n",
    "\n",
    "\n",
    "def getelbow_aggr(ks, val=False):\n",
    "    \"\"\"Elbow using curvature - aggressive\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    ks : array-like\n",
    "\n",
    "    val : bool, optional\n",
    "        Default is False\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    array-like\n",
    "        Either the elbow index (if val is True) or the values at the elbow\n",
    "        index (if val is False)\n",
    "    \"\"\"\n",
    "    ks = np.sort(ks)[::-1]\n",
    "    dKdt = ks[:-1] - ks[1:]\n",
    "    dKdt2 = dKdt[:-1] - dKdt[1:]\n",
    "    curv = np.abs((dKdt2 / (1 + dKdt[:-1]**2.) ** (3. / 2.)))\n",
    "    curv[np.isnan(curv)] = -1 * 10**6\n",
    "    maxcurv = np.argmax(curv) + 2\n",
    "\n",
    "    if val: return(ks[maxcurv])\n",
    "    else:return maxcurv\n",
    "\n",
    "\n",
    "def getfbounds(ne):\n",
    "    \"\"\"\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    ne : int\n",
    "        Number of echoes.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    \"\"\"\n",
    "    if not isinstance(ne, int):\n",
    "        raise IOError('Input ne must be int')\n",
    "    elif ne <= 0:\n",
    "        raise ValueError('Input ne must be greater than 0')\n",
    "\n",
    "    F05s = [None, 18.5, 10.1, 7.7, 6.6, 6.0, 5.6, 5.3, 5.1, 5.0]\n",
    "    F025s = [None, 38.5, 17.4, 12.2, 10, 8.8, 8.1, 7.6, 7.2, 6.9]\n",
    "    F01s = [None, 98.5, 34.1, 21.2, 16.2, 13.8, 12.2, 11.3, 10.7, 10.]\n",
    "    return F05s[ne], F025s[ne], F01s[ne]\n",
    "\n",
    "\n",
    "def eimask(dd, ees=None):\n",
    "    if ees==None: ees=range(dd.shape[1])\n",
    "    imask = np.zeros([dd.shape[0], len(ees)])\n",
    "    for ee in ees:\n",
    "        print(ee)\n",
    "        lthr = 0.001 * stats.scoreatpercentile(dd[:,ee,:].flatten(),98, interpolation_method='lower')\n",
    "        hthr = 5 * stats.scoreatpercentile(dd[:,ee,:].flatten(),98, interpolation_method='lower')\n",
    "        print(lthr,hthr)\n",
    "        imask[dd[:,ee,:].mean(1) > lthr,ee]=1\n",
    "        imask[dd[:,ee,:].mean(1) > hthr,ee]=0\n",
    "    return imask\n",
    "\n",
    "\n",
    "def split_ts(data,comptable,mmix, acc, rej, midk):\n",
    "    cbetas = get_coeffs(data-data.mean(-1)[:,:,:,np.newaxis],mask,mmix)\n",
    "    betas = fmask(cbetas,mask)\n",
    "    if len(acc)!=0:\n",
    "        hikts=unmask(betas[:,acc].dot(mmix.T[acc,:]),mask)\n",
    "    else:\n",
    "        hikts = None\n",
    "    return hikts,data-hikts\n",
    "\n",
    "@jit\n",
    "def computefeats2(data,mmix,mask,normalize=True):\n",
    "    #Write feature versions of components\n",
    "    data = data[mask]\n",
    "    data_vn = (data-data.mean(axis=-1)[:,np.newaxis])/data.std(axis=-1)[:,np.newaxis]\n",
    "    data_R = get_coeffs(unmask(data_vn,mask),mask,mmix)[mask]\n",
    "    data_R[data_R<-.999] = -0.999\n",
    "    data_R[data_R>.999] = .999\n",
    "    data_Z = np.arctanh(data_R)\n",
    "    if len(data_Z.shape)==1: data_Z = np.atleast_2d(data_Z).T\n",
    "    if normalize:\n",
    "        #data_Z2 = ((data_Z.T-data_Z.mean(0)[:,np.newaxis])/data_Z.std(0)[:,np.newaxis]).T\n",
    "        data_Z = (((data_Z.T-data_Z.mean(0)[:,np.newaxis])/data_Z.std(0)[:,np.newaxis])  + (data_Z.mean(0)/data_Z.std(0))[:,np.newaxis]).T\n",
    "    return data_Z\n",
    "\n",
    "\n",
    "def ctabsel(ctabfile):\n",
    "    ctlines = open(ctabfile).readlines()\n",
    "    class_tags = ['#ACC','#REJ','#MID','#IGN']\n",
    "    class_dict = {}\n",
    "    for ii,ll in enumerate(ctlines):\n",
    "        for kk in class_tags:\n",
    "            if ll[:4]==kk and ll[4:].strip() != '':\n",
    "                class_dict[kk] = ll[4:].split('#')[0].split(',')\n",
    "    return tuple([np.array(class_dict[kk],dtype=int) for kk in class_tags])\n",
    "\n",
    "\n",
    "# def dwtmat(mmix):\n",
    "#     print(\"++Wavelet transforming data\")\n",
    "#     llt = len(np.hstack(pywt.dwt(mmix[0],'db2')))\n",
    "#     mmix_wt = np.zeros([mmix.shape[0],llt])\n",
    "#     for ii in range(mmix_wt.shape[0]):\n",
    "#         wtx = pywt.dwt(mmix[ii],'db2')\n",
    "#         #print len(wtx[0]),len(wtx[1])\n",
    "#         cAlen = len(wtx[0])\n",
    "#         mmix_wt[ii] = np.hstack(wtx)\n",
    "#     return mmix_wt,cAlen\n",
    "#\n",
    "#\n",
    "# def idwtmat(mmix_wt,cAl):\n",
    "#     print(\"++Inverse wavelet transforming\")\n",
    "#     lt = len(pywt.idwt(mmix_wt[0,:cAl],mmix_wt[0,cAl:],'db2',correct_size=True))\n",
    "#     mmix_iwt = np.zeros([mmix_wt.shape[0],lt])\n",
    "#     for ii in range(mmix_iwt.shape[0]):\n",
    "#         mmix_iwt[ii] = pywt.idwt(mmix_wt[ii,:cAl],mmix_wt[ii,cAl:],'db2',correct_size=True)\n",
    "#     return mmix_iwt\n",
    "\n",
    "\n",
    "def fitmodels_direct(catd, mmix, mask,\n",
    "                     t2s, t2sG, tes,\n",
    "                     combmode, head, fout=None,\n",
    "                     reindex=False,mmixN=None,\n",
    "                     full_sel=True):\n",
    "    \"\"\"\n",
    "    Usage:\n",
    "\n",
    "    fitmodels_direct(fout)\n",
    "\n",
    "    Input:\n",
    "    fout is flag for output of per-component TE-dependence maps\n",
    "    t2s is a (nx,ny,nz) ndarray\n",
    "    tes is a 1d array\n",
    "    \"\"\"\n",
    "\n",
    "    #Compute opt. com. raw data\n",
    "    tsoc = np.array(optcom(catd, t2sG, tes,\n",
    "                           mask, combmode, useG=True),\n",
    "                    dtype=float)[mask]\n",
    "    tsoc_mean = tsoc.mean(axis=-1)\n",
    "    tsoc_dm = tsoc-tsoc_mean[:,np.newaxis]\n",
    "\n",
    "    #Compute un-normalized weight dataset (features)\n",
    "    if mmixN is None:\n",
    "        mmixN = mmix\n",
    "    #WTS = computefeats2(unmask(unmask(tsoc,mask)[t2s!=0],t2s!=0),mmixN,t2s!=0,normalize=False)\n",
    "    WTS = computefeats2(unmask(tsoc,mask),mmixN,mask,normalize=False)\n",
    "\n",
    "    #Compute PSC dataset - shouldn't have to refit data\n",
    "    global tsoc_B\n",
    "    tsoc_B = get_coeffs(unmask(tsoc_dm,mask),mask,mmix)[mask]\n",
    "    tsoc_Babs = np.abs(tsoc_B)\n",
    "    PSC = tsoc_B/tsoc.mean(axis=-1)[:,np.newaxis]*100\n",
    "\n",
    "    #Compute skews to determine signs based on unnormalized weights, correct mmix & WTS signs based on spatial distribution tails\n",
    "    from scipy.stats import skew\n",
    "    signs = skew(WTS,axis=0)\n",
    "    signs /= np.abs(signs)\n",
    "    mmix = mmix.copy()\n",
    "    mmix*=signs\n",
    "    WTS*=signs\n",
    "    PSC*=signs\n",
    "    totvar = (tsoc_B**2).sum()\n",
    "    totvar_norm = (WTS**2).sum()\n",
    "\n",
    "    #Compute Betas and means over TEs for TE-dependence analysis\n",
    "    Ne = len(tes)\n",
    "    betas = cat2echos(get_coeffs(uncat2echos(catd,Ne),np.tile(mask,(1,1,Ne)),mmix),Ne)\n",
    "    nx,ny,nz,Ne,nc = betas.shape\n",
    "    Nm = mask.sum()\n",
    "    NmD = (t2s!=0).sum()\n",
    "    mu = catd.mean(axis=-1)\n",
    "    tes = np.reshape(tes,(Ne,1))\n",
    "    fmin,fmid,fmax = getfbounds(Ne)\n",
    "\n",
    "    #Mask arrays\n",
    "    mumask   = fmask(mu,t2s!=0)\n",
    "    #t2smask  = fmask(t2s,mask)\n",
    "    t2smask  = fmask(t2s,t2s!=0)\n",
    "    betamask = fmask(betas,t2s!=0)\n",
    "\n",
    "    #Setup Xmats\n",
    "    #Model 1\n",
    "    X1 = mumask.transpose()\n",
    "\n",
    "    #Model 2\n",
    "    X2 = np.tile(tes,(1,NmD))*mumask.transpose()/t2smask.transpose()\n",
    "\n",
    "    #Tables for component selection\n",
    "    global Kappas, Rhos, varex, varex_norm\n",
    "    global Z_maps, F_R2_maps, F_S0_maps\n",
    "    global Z_clmaps, F_R2_clmaps, F_S0_clmaps\n",
    "    global Br_clmaps_R2, Br_clmaps_S0\n",
    "    Kappas = np.zeros([nc])\n",
    "    Rhos = np.zeros([nc])\n",
    "    varex = np.zeros([nc])\n",
    "    varex_norm = np.zeros([nc])\n",
    "    Z_maps = np.zeros([Nm,nc])\n",
    "    F_R2_maps = np.zeros([NmD,nc])\n",
    "    F_S0_maps = np.zeros([NmD,nc])\n",
    "    Z_clmaps = np.zeros([Nm,nc])\n",
    "    F_R2_clmaps = np.zeros([NmD,nc])\n",
    "    F_S0_clmaps = np.zeros([NmD,nc])\n",
    "    Br_clmaps_R2 = np.zeros([Nm,nc])\n",
    "    Br_clmaps_S0 = np.zeros([Nm,nc])\n",
    "\n",
    "    for i in range(nc):\n",
    "\n",
    "        #size of B is (nc, nx*ny*nz)\n",
    "        B = np.atleast_3d(betamask)[:,:,i].transpose()\n",
    "        alpha = (np.abs(B)**2).sum(axis=0)\n",
    "        varex[i] = (tsoc_B[:,i]**2).sum()/totvar*100.\n",
    "        varex_norm[i] = (unmask(WTS,mask)[t2s!=0][:,i]**2).sum()/totvar_norm*100.\n",
    "\n",
    "        #S0 Model\n",
    "        coeffs_S0 = (B*X1).sum(axis=0)/(X1**2).sum(axis=0)\n",
    "        SSE_S0 = (B - X1*np.tile(coeffs_S0,(Ne,1)))**2\n",
    "        SSE_S0 = SSE_S0.sum(axis=0)\n",
    "        F_S0 = (alpha - SSE_S0)*2/(SSE_S0)\n",
    "        F_S0_maps[:,i] = F_S0\n",
    "\n",
    "        #R2 Model\n",
    "        coeffs_R2 = (B*X2).sum(axis=0)/(X2**2).sum(axis=0)\n",
    "        SSE_R2 = (B - X2*np.tile(coeffs_R2,(Ne,1)))**2\n",
    "        SSE_R2 = SSE_R2.sum(axis=0)\n",
    "        F_R2 = (alpha - SSE_R2)*2/(SSE_R2)\n",
    "        F_R2_maps[:,i] = F_R2\n",
    "\n",
    "        #Compute weights as Z-values\n",
    "        wtsZ=(WTS[:,i]-WTS[:,i].mean())/WTS[:,i].std()\n",
    "        wtsZ[np.abs(wtsZ)>Z_MAX]=(Z_MAX*(np.abs(wtsZ)/wtsZ))[np.abs(wtsZ)>Z_MAX]\n",
    "        Z_maps[:,i] = wtsZ\n",
    "\n",
    "        #Compute Kappa and Rho\n",
    "        F_S0[F_S0>F_MAX] = F_MAX\n",
    "        F_R2[F_R2>F_MAX] = F_MAX\n",
    "        Kappas[i] = np.average(F_R2,weights=np.abs(np.squeeze(unmask(wtsZ,mask)[t2s!=0]**2.)))\n",
    "        Rhos[i] = np.average(F_S0,weights=np.abs(np.squeeze(unmask(wtsZ,mask)[t2s!=0]**2.)))\n",
    "\n",
    "    #Tabulate component values\n",
    "    comptab_pre = np.vstack([np.arange(nc),Kappas,Rhos,varex,varex_norm]).T\n",
    "    if reindex:\n",
    "        #Re-index all components in Kappa order\n",
    "        comptab = comptab_pre[comptab_pre[:,1].argsort()[::-1],:]\n",
    "        Kappas = comptab[:,1]; Rhos = comptab[:,2]; varex = comptab[:,3]; varex_norm = comptab[:,4]\n",
    "        nnc = np.array(comptab[:,0],dtype=np.int)\n",
    "        mmix_new = mmix[:,nnc]\n",
    "        F_S0_maps = F_S0_maps[:,nnc]; F_R2_maps = F_R2_maps[:,nnc]; Z_maps = Z_maps[:,nnc]\n",
    "        WTS = WTS[:,nnc]; PSC=PSC[:,nnc]; tsoc_B=tsoc_B[:,nnc]; tsoc_Babs=tsoc_Babs[:,nnc]\n",
    "        comptab[:,0] = np.arange(comptab.shape[0])\n",
    "    else:\n",
    "        comptab = comptab_pre\n",
    "        mmix_new = mmix\n",
    "\n",
    "    #Full selection including clustering criteria\n",
    "    seldict=None\n",
    "    if full_sel:\n",
    "        for i in range(nc):\n",
    "\n",
    "            #Save out files\n",
    "            out = np.zeros((nx,ny,nz,4))\n",
    "            if fout!=None:\n",
    "                ccname = \"cc%.3d.nii\" % i\n",
    "            else: ccname = \".cc_temp.nii.gz\"\n",
    "\n",
    "            out[:,:,:,0] = np.squeeze(unmask(PSC[:,i],mask))\n",
    "            out[:,:,:,1] = np.squeeze(unmask(F_R2_maps[:,i],t2s!=0))\n",
    "            out[:,:,:,2] = np.squeeze(unmask(F_S0_maps[:,i],t2s!=0))\n",
    "            out[:,:,:,3] = np.squeeze(unmask(Z_maps[:,i],mask))\n",
    "\n",
    "            niwrite(out,fout,ccname,head)\n",
    "            os.system('3drefit -sublabel 0 PSC -sublabel 1 F_R2  -sublabel 2 F_SO -sublabel 3 Z_sn %s 2> /dev/null > /dev/null'%ccname)\n",
    "\n",
    "            csize = np.max([int(Nm*0.0005)+5,20])\n",
    "            #csize = 10\n",
    "\n",
    "            #Do simple clustering on F\n",
    "            os.system(\"3dcalc -overwrite -a %s[1..2] -expr 'a*step(a-%i)' -prefix .fcl_in.nii.gz -overwrite\" % (ccname,fmin))\n",
    "            os.system('3dmerge -overwrite -dxyz=1 -1clust 1 %i -doall -prefix .fcl_out.nii.gz .fcl_in.nii.gz' % (csize))\n",
    "            sel = fmask(nib.load('.fcl_out.nii.gz').get_data(),t2s!=0)!=0\n",
    "            sel = np.array(sel,dtype=np.int)\n",
    "            F_R2_clmaps[:,i] = sel[:,0]\n",
    "            F_S0_clmaps[:,i] = sel[:,1]\n",
    "\n",
    "            #Do simple clustering on Z at p<0.05\n",
    "            sel = spatclust(None,mask,csize,1.95,head,aff,infile=ccname,dindex=3,tindex=3)\n",
    "            Z_clmaps[:,i] = sel\n",
    "\n",
    "            #Do simple clustering on ranked signal-change map\n",
    "            countsigFR2 = F_R2_clmaps[:,i].sum()\n",
    "            countsigFS0 = F_S0_clmaps[:,i].sum()\n",
    "            Br_clmaps_R2[:,i] = spatclust(rankvec(tsoc_Babs[:,i]),mask,csize,max(tsoc_Babs.shape)-countsigFR2,head,aff)\n",
    "            Br_clmaps_S0[:,i] = spatclust(rankvec(tsoc_Babs[:,i]),mask,csize,max(tsoc_Babs.shape)-countsigFS0,head,aff)\n",
    "\n",
    "        seldict = {}\n",
    "        selvars = ['Kappas','Rhos','WTS','varex','Z_maps','F_R2_maps','F_S0_maps',\\\n",
    "            'Z_clmaps','F_R2_clmaps','F_S0_clmaps','tsoc_B','Br_clmaps_R2','Br_clmaps_S0','PSC']\n",
    "        for vv in selvars:\n",
    "            seldict[vv] = eval(vv)\n",
    "\n",
    "    return seldict,comptab,betas,mmix_new\n",
    "\n",
    "\n",
    "def selcomps(seldict, mmix, head, debug=False, olevel=2, oversion=99, knobargs='',\n",
    "         filecsdata=False, savecsdiag=True, group0_only=False,\n",
    "         strict_mode=False):\n",
    "\n",
    "    import numpy.fft as fft\n",
    "    from sklearn.cluster import DBSCAN\n",
    "\n",
    "    \"\"\"\n",
    "    Set knobs\n",
    "    \"\"\"\n",
    "    if knobargs is not '':\n",
    "        knobs = vars(knobargs)\n",
    "        locals().update(knobs)\n",
    "\n",
    "    try:\n",
    "        if filecsdata: filecsdata=True\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    if filecsdata:\n",
    "        import bz2\n",
    "        if seldict is not None:\n",
    "            print(\"Saving component selection data\")\n",
    "            csstate_f = bz2.BZ2File('compseldata.pklbz','wb')\n",
    "            pickle.dump(seldict,csstate_f)\n",
    "            csstate_f.close()\n",
    "        else:\n",
    "            try:\n",
    "                csstate_f = bz2.BZ2File('compseldata.pklbz','rb')\n",
    "                seldict = pickle.load(csstate_f)\n",
    "                csstate_f.close()\n",
    "            except:\n",
    "                print(\"No component data found!\")\n",
    "                return None\n",
    "\n",
    "    #Dump dictionary into variable names\n",
    "    for key in seldict.keys(): exec(\"%s=seldict['%s']\" % (key,key))\n",
    "\n",
    "    #List of components\n",
    "    midk = []\n",
    "    ign = []\n",
    "    nc = np.arange(len(Kappas))\n",
    "    ncl = np.arange(len(Kappas))\n",
    "\n",
    "    #If user has specified components to accept manually\n",
    "    try:\n",
    "        if manacc:\n",
    "            acc = sorted([int(vv) for vv in manacc.split(',')])\n",
    "            midk = []\n",
    "            rej = sorted(np.setdiff1d(ncl,acc))\n",
    "            return acc,rej,midk,[] #Add string for ign\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    \"\"\"\n",
    "    Do some tallies for no. of significant voxels\n",
    "    \"\"\"\n",
    "    countsigZ = Z_clmaps.sum(0)\n",
    "    countsigFS0 = F_S0_clmaps.sum(0)\n",
    "    countsigFR2 = F_R2_clmaps.sum(0)\n",
    "    countnoise = np.zeros(len(nc))\n",
    "\n",
    "    \"\"\"\n",
    "    Make table of dice values\n",
    "    \"\"\"\n",
    "    dice_table = np.zeros([nc.shape[0],2])\n",
    "    csize = np.max([int(mask.sum()*0.0005)+5,20])\n",
    "    for ii in ncl:\n",
    "        dice_FR2 = dice(unmask(Br_clmaps_R2[:,ii],mask)[t2s!=0],F_R2_clmaps[:,ii])\n",
    "        dice_FS0 = dice(unmask(Br_clmaps_S0[:,ii],mask)[t2s!=0],F_S0_clmaps[:,ii])\n",
    "        dice_table[ii,:] = [dice_FR2,dice_FS0] #step 3a here and above\n",
    "    dice_table[np.isnan(dice_table)]=0\n",
    "\n",
    "    \"\"\"\n",
    "    Make table of noise gain\n",
    "    \"\"\"\n",
    "    tt_table = np.zeros([len(nc),4])\n",
    "    counts_FR2_Z = np.zeros([len(nc),2])\n",
    "    for ii in nc:\n",
    "        comp_noise_sel = andb([np.abs(Z_maps[:,ii])>1.95,Z_clmaps[:,ii]==0])==2\n",
    "        countnoise[ii] = np.array(comp_noise_sel,dtype=np.int).sum()\n",
    "        noise_FR2_Z = np.log10(np.unique(F_R2_maps[unmask(comp_noise_sel,mask)[t2s!=0],ii]))\n",
    "        signal_FR2_Z  = np.log10(np.unique(F_R2_maps[unmask(Z_clmaps[:,ii],mask)[t2s!=0]==1,ii]))\n",
    "        counts_FR2_Z[ii,:] = [len(signal_FR2_Z),len(noise_FR2_Z)]\n",
    "        try:\n",
    "            ttest = stats.ttest_ind(signal_FR2_Z,noise_FR2_Z,equal_var=True)\n",
    "            mwu = stats.norm.ppf(stats.mannwhitneyu(signal_FR2_Z,noise_FR2_Z)[1])\n",
    "            tt_table[ii,0] = np.abs(mwu)*ttest[0]/np.abs(ttest[0])\n",
    "            tt_table[ii,1] = ttest[1]\n",
    "        except: pass\n",
    "    tt_table[np.isnan(tt_table)]=0\n",
    "    tt_table[np.isinf(tt_table[:,0]),0]=np.percentile(tt_table[~np.isinf(tt_table[:,0]),0],98)\n",
    "\n",
    "    #Time series derivative kurtosis\n",
    "    mmix_dt = (mmix[:-1]-mmix[1:])\n",
    "    mmix_kurt = stats.kurtosis(mmix_dt)\n",
    "    mmix_std = np.std(mmix_dt,0)\n",
    "\n",
    "    \"\"\"\n",
    "    Step 1: Reject anything that's obviously an artifact\n",
    "    a. Estimate a null variance\n",
    "    \"\"\"\n",
    "    rej = ncl[andb([Rhos>Kappas,countsigFS0>countsigFR2])>0]\n",
    "    ncl = np.setdiff1d(ncl,rej)\n",
    "\n",
    "    \"\"\"\n",
    "    Step 2: Compute 3-D spatial FFT of Beta maps to detect high-spatial frequency artifacts\n",
    "    \"\"\"\n",
    "    fproj_arr = np.zeros([np.prod(mask.shape[0:2]),len(nc)])\n",
    "    fproj_arr_val = np.zeros([np.prod(mask.shape[0:2]),len(nc)])\n",
    "    spr = []\n",
    "    fdist = []\n",
    "    for ii in nc:\n",
    "        fproj = np.fft.fftshift(np.abs(np.fft.rfftn(unmask(seldict['PSC'],mask)[:,:,:,ii])))\n",
    "        fproj_z = fproj.max(2)\n",
    "        fproj[fproj==fproj.max()] = 0\n",
    "        fproj_arr[:,ii] = rankvec(fproj_z.flatten())\n",
    "        fproj_arr_val[:,ii] = fproj_z.flatten()\n",
    "        spr.append(np.array(fproj_z>fproj_z.max()/4,dtype=np.int).sum())\n",
    "        fprojr = np.array([fproj,fproj[:,:,::-1]]).max(0)\n",
    "        fdist.append(np.max([ fitgaussian(fproj.max(jj))[3:].max() for jj in range(len(fprojr.shape)) ]))\n",
    "    fdist = np.array(fdist)\n",
    "    spr = np.array(spr)\n",
    "\n",
    "    \"\"\"\n",
    "    Step 3: Create feature space of component properties\n",
    "    \"\"\"\n",
    "    fdist_pre = fdist.copy()\n",
    "    fdist_pre[fdist>np.median(fdist)*3] = np.median(fdist)*3\n",
    "    fdist_z = (fdist_pre - np.median(fdist_pre) ) / fdist_pre.std()\n",
    "    spz = (spr-spr.mean())/spr.std()\n",
    "    Tz = (tt_table[:,0]-tt_table[:,0].mean())/tt_table[:,0].std()\n",
    "    varex_ = np.log(varex)\n",
    "    Vz = (varex_-varex_.mean())/varex_.std()\n",
    "    Kz = (Kappas-Kappas.mean())/Kappas.std()\n",
    "    Rz = (Rhos-Rhos.mean())/Rhos.std()\n",
    "    Ktz = np.log(Kappas)/2\n",
    "    Ktz = (Ktz-Ktz.mean())/Ktz.std()\n",
    "    Rtz = np.log(Rhos)/2\n",
    "    Rtz = (Rtz-Rtz.mean())/Rtz.std()\n",
    "    KRr = stats.zscore(np.log(Kappas)/np.log(Rhos))\n",
    "    cnz = (countnoise-countnoise.mean())/countnoise.std()\n",
    "    Dz = stats.zscore(np.arctanh(dice_table[:,0]+0.001))\n",
    "    fz = np.array([Tz,Vz,Ktz,KRr,cnz,Rz,mmix_kurt,fdist_z])\n",
    "\n",
    "    \"\"\"\n",
    "    Step 3: Make initial guess of where BOLD components are and use DBSCAN to exclude noise components and find a sample set of 'good' components\n",
    "    \"\"\"\n",
    "    #epsmap is [index,level of overlap with dicemask,number of high Rho components]\n",
    "    F05,F025,F01 = getfbounds(ne)\n",
    "    epsmap = []\n",
    "    Rhos_sorted = np.array(sorted(Rhos))[::-1]\n",
    "    #Make an initial guess as to number of good components based on consensus of control points across Rhos and Kappas\n",
    "    KRcutguesses = [getelbow_mod(Rhos),getelbow_cons(Rhos),getelbow_aggr(Rhos),getelbow_mod(Kappas),getelbow_cons(Kappas),getelbow_aggr(Kappas)]\n",
    "    Kelbowval = np.median([getelbow_mod(Kappas,val=True),getelbow_cons(Kappas,val=True),getelbow_aggr(Kappas,val=True)]+list(getfbounds(ne)))\n",
    "    Khighelbowval = stats.scoreatpercentile([getelbow_mod(Kappas,val=True),getelbow_cons(Kappas,val=True),getelbow_aggr(Kappas,val=True)]+list(getfbounds(ne)),75, interpolation_method='lower')\n",
    "    KRcut = np.median(KRcutguesses)\n",
    "    #only use exclusive when inclusive is extremely inclusive - double KRcut\n",
    "    if getelbow_cons(Kappas) > KRcut*2 and getelbow_mod(Kappas,val=True)<F01: Kcut = getelbow_mod(Kappas,val=True)\n",
    "    else: Kcut = getelbow_cons(Kappas,val=True)\n",
    "    #only use inclusive when exclusive is extremely exclusive - half KRcut (remember for Rho inclusive is higher, so want both Kappa and Rho to defaut to lower)\n",
    "    if getelbow_cons(Rhos) > KRcut*2 : Rcut = getelbow_mod(Rhos,val=True) #consider something like min([getelbow_mod(Rhos,True),sorted(Rhos)[::-1][KRguess] ])\n",
    "    else: Rcut = getelbow_cons(Rhos,val=True)\n",
    "    if Rcut > Kcut: Kcut = Rcut #Rcut should never be higher than Kcut\n",
    "    KRelbow = andb([Kappas>Kcut,Rhos<Rcut ] )\n",
    "    #Make guess of Kundu et al 2011 plus remove high frequencies, generally high variance, and high variance given low Kappa\n",
    "    tt_lim = stats.scoreatpercentile(tt_table[tt_table[:,0]>0,0],75, interpolation_method='lower')/3\n",
    "    KRguess = np.setdiff1d(np.setdiff1d(nc[KRelbow==2],rej),np.union1d(nc[tt_table[:,0]<tt_lim],np.union1d(np.union1d(nc[spz>1],nc[Vz>2]),nc[andb([varex>0.5*sorted(varex)[::-1][int(KRcut)],Kappas<2*Kcut])==2])))\n",
    "    guessmask = np.zeros(len(nc))\n",
    "    guessmask[KRguess] = 1\n",
    "\n",
    "    #Throw lower-risk bad components out\n",
    "    rejB = ncl[andb([tt_table[ncl,0]<0,varex[ncl]>np.median(varex),ncl > KRcut])==3]\n",
    "    rej = np.union1d(rej,rejB)\n",
    "    ncl = np.setdiff1d(ncl,rej)\n",
    "\n",
    "    for ii in range(20000):\n",
    "        db = DBSCAN(eps=.005+ii*.005, min_samples=3).fit(fz.T)\n",
    "        if db.labels_.max() > 1 and db.labels_.max() < len(nc)/6 and np.intersect1d(rej,nc[db.labels_==0]).shape[0]==0 and np.array(db.labels_==-1,dtype=int).sum()/float(len(nc))<.5:\n",
    "            epsmap.append([ii, dice(guessmask,db.labels_==0),np.intersect1d(nc[db.labels_==0],nc[Rhos>getelbow_mod(Rhos_sorted,val=True)]).shape[0]   ])\n",
    "            if debug: print(\"found solution\", ii, db.labels_)\n",
    "        db = None\n",
    "\n",
    "    epsmap = np.array(epsmap)\n",
    "    group0 = []\n",
    "    dbscanfailed=False\n",
    "    if len(epsmap)!=0 :\n",
    "        #Select index that maximizes Dice with guessmask but first minimizes number of higher Rho components\n",
    "        ii = int(epsmap[np.argmax(epsmap[epsmap[:,2]==np.min(epsmap[:,2]),1],0),0])\n",
    "        print('Component selection tuning: ' , epsmap[:,1].max())\n",
    "        db = DBSCAN(eps=.005+ii*.005, min_samples=3).fit(fz.T)\n",
    "        ncl = nc[db.labels_==0]\n",
    "        ncl = np.setdiff1d(ncl,rej)\n",
    "        ncl = np.setdiff1d(ncl,ncl[ncl>len(nc)-len(rej)])\n",
    "        group0 = ncl.copy()\n",
    "        group_n1 = nc[db.labels_==-1]\n",
    "        to_clf = np.setdiff1d(nc,np.union1d(ncl,rej))\n",
    "    if len(group0)==0 or len(group0) < len(KRguess)*.5:\n",
    "        dbscanfailed=True\n",
    "        print(\"DBSCAN based guess failed. Using elbow guess method.\")\n",
    "        ncl = np.setdiff1d(np.setdiff1d(nc[KRelbow==2],rej),np.union1d(nc[tt_table[:,0]<tt_lim],np.union1d(np.union1d(nc[spz>1],nc[Vz>2]),nc[andb([varex>0.5*sorted(varex)[::-1][int(KRcut)],Kappas<2*Kcut])==2])))\n",
    "        group0 = ncl.copy()\n",
    "        group_n1 = []\n",
    "        to_clf = np.setdiff1d(nc,np.union1d(group0,rej))\n",
    "    if len(group0)<2 or (len(group0)<4 and float(len(rej))/len(group0)>3):\n",
    "        print(\"WARNING: Extremely limited reliable BOLD signal space. Not filtering further into midk etc.\")\n",
    "        midkfailed = True\n",
    "        min_acc = np.array([])\n",
    "        if len(group0)!=0:\n",
    "            toacc_hi = np.setdiff1d(nc [andb([ fdist <= np.max(fdist[group0]), Rhos<F025, Vz>-2 ])==3  ],np.union1d(group0,rej)) #For extremes, building in a 20% tolerance\n",
    "            min_acc = np.union1d(group0,toacc_hi)\n",
    "            to_clf = np.setdiff1d(nc , np.union1d(min_acc,rej) )\n",
    "        diagstepkeys=['rej','KRcut','Kcut','Rcut','dbscanfailed','midkfailed','KRguess','group0','min_acc','toacc_hi']\n",
    "        diagstepout=[]\n",
    "        for ddk in diagstepkeys: diagstepout.append(\"%s: %s\" %  (ddk,eval('str(%s)' % ddk) ) )\n",
    "        with open('csstepdata.txt','w') as ofh:\n",
    "            ofh.write('\\n'.join(diagstepout))\n",
    "        ofh.close()\n",
    "        return list(sorted(min_acc)),list(sorted(rej)),[],list(sorted(to_clf))\n",
    "\n",
    "    if group0_only: return list(sorted(group0)),list(sorted(rej)),[],list(sorted(to_clf))\n",
    "\n",
    "    #Find additional components to reject based on Dice - doing this here since Dice is a little unstable, need to reference group0\n",
    "    rej_supp = []\n",
    "    dice_rej = False\n",
    "    if not dbscanfailed and len(rej)+len(group0)<0.75*len(nc):\n",
    "        dice_rej = True\n",
    "        rej_supp = np.setdiff1d(np.setdiff1d(np.union1d(rej,nc[dice_table[nc,0]<=dice_table[nc,1]]  ),group0),group_n1)\n",
    "        rej = np.union1d(rej,rej_supp)\n",
    "\n",
    "    #Temporal features\n",
    "    mmix_kurt_z = (mmix_kurt-mmix_kurt[group0].mean())/mmix_kurt[group0].std()   #larger is worse - spike\n",
    "    mmix_std_z = -1*((mmix_std-mmix_std[group0].mean())/mmix_std[group0].std())  #smaller is worse - drift\n",
    "    mmix_kurt_z_max  = np.max([mmix_kurt_z,mmix_std_z],0)\n",
    "\n",
    "    \"\"\"\n",
    "    Step 2: Classifiy midk and ignore using separte SVMs for difference variance regimes\n",
    "    #To render hyperplane:\n",
    "    min_x = np.min(spz2);max_x=np.max(spz2)\n",
    "    # plotting separating hyperplane\n",
    "        ww = clf_.coef_[0]\n",
    "        aa = -ww[0] / ww[1]\n",
    "        xx = np.linspace(min_x - 2, max_x + 2)  # make sure the line is long enough\n",
    "        yy = aa * xx - (clf_.intercept_[0]) / ww[1]\n",
    "        plt.plot(xx, yy, '-')\n",
    "    \"\"\"\n",
    "\n",
    "    toacc_hi = np.setdiff1d(nc [andb([ fdist <= np.max(fdist[group0]), Rhos<F025, Vz>-2 ])==3  ],np.union1d(group0,rej))  #Tried getting rid of accepting based on SVM altogether, now using only rejecting\n",
    "    toacc_lo = np.intersect1d(to_clf,nc[andb([spz<1,Rz<0,mmix_kurt_z_max<5,Dz>-1,Tz>-1,Vz<0,Kappas>=F025,fdist<3*np.percentile(fdist[group0],98)])==8])\n",
    "    midk_clf,clf_ = do_svm(fproj_arr_val[:, np.union1d(group0, rej)].T,\n",
    "                           [0] * len(group0) + [1] * len(rej),\n",
    "                           fproj_arr_val[:, to_clf].T,\n",
    "                           svmtype=2)\n",
    "    midk = np.setdiff1d(to_clf[andb([midk_clf==1,varex[to_clf]>np.median(varex[group0])  ])==2],np.union1d(toacc_hi,toacc_lo))\n",
    "    if len(np.intersect1d(to_clf[andb([midk_clf==1,Vz[to_clf]>0 ])==2],toacc_hi))==0:\n",
    "        svm_acc_fail = True\n",
    "        toacc_hi = np.union1d(toacc_hi,to_clf[midk_clf==0])  #only use SVM to augment toacc_hi only if toacc_hi isn't already conflicting with SVM choice\n",
    "    else: svm_acc_fail = False\n",
    "\n",
    "    \"\"\"\n",
    "    Step 3: Compute variance associated with low T2* areas (e.g. draining veins and low T2* areas)\n",
    "    #To write out veinmask\n",
    "    veinout = np.zeros(t2s.shape)\n",
    "    veinout[t2s!=0] = veinmaskf\n",
    "    niwrite(veinout,aff,'veinmaskf.nii',head)\n",
    "    veinBout = unmask(veinmaskB,mask)\n",
    "    niwrite(veinBout,aff,'veins50.nii',head)\n",
    "    \"\"\"\n",
    "\n",
    "    tsoc_B_Zcl = np.zeros(tsoc_B.shape)\n",
    "    tsoc_B_Zcl[Z_clmaps!=0] = np.abs(tsoc_B)[Z_clmaps!=0]\n",
    "    sig_B = [ stats.scoreatpercentile(tsoc_B_Zcl[tsoc_B_Zcl[:,ii]!=0,ii],25) if len(tsoc_B_Zcl[tsoc_B_Zcl[:,ii]!=0,ii]) != 0  else 0 for ii in nc   ]\n",
    "    sig_B = np.abs(tsoc_B)>np.tile(sig_B,[tsoc_B.shape[0],1])\n",
    "\n",
    "    veinmask = andb([t2s<stats.scoreatpercentile(t2s[t2s != 0],15, interpolation_method='lower'),t2s != 0]) == 2\n",
    "    veinmaskf = veinmask[mask]\n",
    "    veinR = np.array(sig_B[veinmaskf].sum(0),dtype=float)/sig_B[~veinmaskf].sum(0)\n",
    "    veinR[np.isnan(veinR)] = 0\n",
    "\n",
    "    veinc = np.union1d(rej,midk)\n",
    "    rej_veinRZ = ((veinR-veinR[veinc].mean())/veinR[veinc].std())[veinc]\n",
    "    rej_veinRZ[rej_veinRZ<0] = 0\n",
    "    rej_veinRZ[ countsigFR2[veinc] > np.array(veinmaskf,dtype=int).sum()] =0\n",
    "    t2s_lim = [stats.scoreatpercentile(t2s[t2s!=0],50, interpolation_method='lower'),\n",
    "               stats.scoreatpercentile(t2s[t2s!=0],80, interpolation_method='lower')/2]\n",
    "    phys_var_zs = []\n",
    "    for t2sl_i in range(len(t2s_lim)):\n",
    "        t2sl = t2s_lim[t2sl_i]\n",
    "        veinW = sig_B[:,veinc]*np.tile(rej_veinRZ,[sig_B.shape[0],1])\n",
    "        veincand = fmask(unmask(andb([s0[t2s!=0]<np.median(s0[t2s!=0]),t2s[t2s!=0]<t2sl])>=1,t2s!=0),mask)\n",
    "        veinW[~veincand]=0\n",
    "        invein = veinW.sum(1)[fmask(unmask(veinmaskf,mask)*unmask(veinW.sum(1)>1,mask),mask)]\n",
    "        minW = 10*(np.log10(invein).mean())-1*10**(np.log10(invein).std())\n",
    "        veinmaskB = veinW.sum(1)>minW\n",
    "        tsoc_Bp = tsoc_B.copy()\n",
    "        tsoc_Bp[tsoc_Bp<0]=0\n",
    "        sig_Bp = sig_B*tsoc_Bp>0\n",
    "        vvex = np.array([(tsoc_Bp[veinmaskB,ii]**2.).sum()/(tsoc_Bp[:,ii]**2.).sum() for ii in nc])\n",
    "        group0_res = np.intersect1d(KRguess,group0)\n",
    "        phys_var_zs.append( (vvex-vvex[group0_res].mean())/vvex[group0_res].std() )\n",
    "        veinBout = unmask(veinmaskB,mask)\n",
    "        niwrite(veinBout,aff,'veins_l%i.nii' % t2sl_i,head)\n",
    "    #Mask to sample veins\n",
    "    phys_var_z = np.array(phys_var_zs).max(0)\n",
    "    Vz2 = (varex_ - varex_[group0].mean())/varex_[group0].std()\n",
    "\n",
    "    \"\"\"\n",
    "    Step 4: Learn joint TE-dependence spatial and temporal models to move remaining artifacts to ignore class\n",
    "    \"\"\"\n",
    "\n",
    "    to_ign = []\n",
    "\n",
    "    minK_ign = np.max([F05,getelbow_cons(Kappas,val=True)])\n",
    "    newcest = len(group0)+len(toacc_hi[ Kappas[toacc_hi]>minK_ign ])\n",
    "    phys_art = np.setdiff1d(nc[andb([phys_var_z>3.5,Kappas<minK_ign])==2],group0)\n",
    "    phys_art = np.union1d(np.setdiff1d(nc[andb([phys_var_z>2,rankvec(phys_var_z)-rankvec(Kappas)>newcest/2,Vz2>-1])==3],group0),phys_art)\n",
    "    #Want to replace field_art with an acf/SVM based approach instead of a kurtosis/filter one\n",
    "    field_art = np.setdiff1d(nc[andb([mmix_kurt_z_max>5,Kappas<minK_ign])==2],group0)\n",
    "    field_art = np.union1d(np.setdiff1d(nc[andb([mmix_kurt_z_max>2,rankvec(mmix_kurt_z_max)-rankvec(Kappas)>newcest/2,Vz2>1,Kappas<F01])==4],group0),field_art)\n",
    "    field_art = np.union1d(np.setdiff1d(nc[andb([mmix_kurt_z_max>3,Vz2>3,Rhos>np.percentile(Rhos[group0],75)  ])==3],group0),field_art)\n",
    "    field_art = np.union1d(np.setdiff1d(nc[andb([mmix_kurt_z_max>5,Vz2>5  ])==2],group0),field_art)\n",
    "    misc_art = np.setdiff1d(nc[andb([(rankvec(Vz)-rankvec(Ktz))>newcest/2,Kappas<Khighelbowval])==2],group0)\n",
    "    ign_cand = np.unique(list(field_art)+list(phys_art)+list(misc_art))\n",
    "    g0_red = np.setdiff1d(group0,ign_cand)\n",
    "    midkrej = np.union1d(midk,rej)\n",
    "    to_ign = np.setdiff1d(list(ign_cand),midkrej)\n",
    "    toacc = np.union1d(toacc_hi,toacc_lo)\n",
    "    ncl = np.setdiff1d(np.union1d(ncl,toacc),np.union1d(to_ign,midkrej))\n",
    "    ign = np.setdiff1d(nc,list(ncl)+list(midk)+list(rej))\n",
    "    orphan = np.setdiff1d(nc,list(ncl)+list(to_ign)+list(midk)+list(rej))\n",
    "\n",
    "    #Last ditch effort to save some transient components\n",
    "    if not strict_mode:\n",
    "        Vz3 = (varex_ - varex_[ncl].mean())/varex_[ncl].std()\n",
    "        ncl = np.union1d(ncl,np.intersect1d(orphan,nc[andb([Kappas>F05,Rhos<F025,Kappas>Rhos,Vz3<=-1,Vz3>-3,mmix_kurt_z_max<2.5])==6]))\n",
    "        ign = np.setdiff1d(nc,list(ncl)+list(midk)+list(rej))\n",
    "        orphan = np.setdiff1d(nc,list(ncl)+list(to_ign)+list(midk)+list(rej))\n",
    "\n",
    "    if savecsdiag:\n",
    "        diagstepkeys=['rej','KRcut','Kcut','Rcut','dbscanfailed','KRguess','group0','dice_rej','rej_supp','to_clf','midk', 'svm_acc_fail', 'toacc_hi','toacc_lo','field_art','phys_art','misc_art','ncl','ign']\n",
    "        diagstepout=[]\n",
    "        for ddk in diagstepkeys: diagstepout.append(\"%s: %s\" %  (ddk,eval('str(%s)' % ddk) ) )\n",
    "        with open('csstepdata.txt','w') as ofh:\n",
    "            ofh.write('\\n'.join(diagstepout))\n",
    "        allfz = np.array([Tz,Vz,Ktz,KRr,cnz,Rz,mmix_kurt,fdist_z])\n",
    "        np.savetxt('csdata.txt',allfz)\n",
    "\n",
    "    return list(sorted(ncl)),list(sorted(rej)),list(sorted(midk)),list(sorted(ign))\n",
    "\n",
    "\n",
    "def tedpca(combmode, mask, stabilize, head, ste=0, mlepca=True):\n",
    "    nx,ny,nz,ne,nt = catd.shape\n",
    "    ste = np.array([int(ee) for ee in str(ste).split(',')])\n",
    "    cAl = None\n",
    "    if len(ste) == 1 and ste[0]==-1:\n",
    "        print(\"-Computing PCA of optimally combined multi-echo data\")\n",
    "        OCmask = make_mask(OCcatd[:,:,:,np.newaxis,:])\n",
    "        d = fmask(OCcatd,OCmask)\n",
    "        eim = eimask(d[:,np.newaxis,:])\n",
    "        eim = eim[:,0]==1\n",
    "        d = d[eim,:]\n",
    "    elif len(ste) == 1 and ste[0]==0:\n",
    "        print(\"-Computing PCA of spatially concatenated multi-echo data\")\n",
    "        ste = np.arange(ne)\n",
    "        d = np.float64(fmask(catd,mask))\n",
    "        eim = eimask(d)==1\n",
    "        d = d[eim]\n",
    "    else:\n",
    "        print(\"-Computing PCA of TE #%s\" % ','.join([str(ee) for ee in ste]))\n",
    "        d = np.float64(np.concatenate([fmask(catd[:,:,:,ee,:],mask)[:,np.newaxis,:] for ee in ste-1],axis=1))\n",
    "        eim = eimask(d)==1\n",
    "        eim = np.squeeze(eim)\n",
    "        d = np.squeeze(d[eim])\n",
    "\n",
    "    dz = ((d.T-d.T.mean(0))/d.T.std(0)).T #Variance normalize timeseries\n",
    "    dz = (dz-dz.mean())/dz.std() #Variance normalize everything\n",
    "\n",
    "    #if wvpca:\n",
    "    #   print \"++Transforming time series from time domain to wavelet domain.\"\n",
    "    #   dz,cAl = dwtmat(dz)\n",
    "\n",
    "    pcastate_fn = 'pcastate.pklgz'\n",
    "\n",
    "    if not os.path.exists(pcastate_fn):\n",
    "        ##Do PC dimension selection\n",
    "        #Get eigenvalue cutoff\n",
    "\n",
    "        if mlepca:\n",
    "            from sklearn.decomposition import PCA\n",
    "            ppca = PCA(n_components='mle',svd_solver='full')\n",
    "            #ppca = PCA(n_components='mle')\n",
    "            ppca.fit(dz)\n",
    "            v = ppca.components_\n",
    "            s = ppca.explained_variance_\n",
    "            u = np.dot(np.dot(dz,v.T),np.diag(1./s))\n",
    "        else:\n",
    "            u,s,v = np.linalg.svd(dz,full_matrices=0)\n",
    "\n",
    "        sp = s/s.sum()\n",
    "        eigelb = sp[getelbow_mod(sp)]\n",
    "\n",
    "        spdif = np.abs(sp[1:]-sp[:-1])\n",
    "        spdifh = spdif[(spdif.shape[0]//2):]\n",
    "        spdmin = spdif.min()\n",
    "        spdthr = np.mean([spdifh.max(),spdmin])\n",
    "        spmin = sp[(spdif.shape[0]//2)+(np.arange(spdifh.shape[0])[spdifh>=spdthr][0])+1]\n",
    "        spcum = []\n",
    "        spcumv = 0\n",
    "        for sss in sp:\n",
    "            spcumv+=sss\n",
    "            spcum.append(spcumv)\n",
    "        spcum = np.array(spcum)\n",
    "\n",
    "        #Compute K and Rho for PCA comps\n",
    "\n",
    "        eimum = np.atleast_2d(eim)\n",
    "        eimum = np.transpose(eimum,np.argsort(np.atleast_2d(eim).shape)[::-1])\n",
    "        eimum = np.array(np.squeeze(unmask(eimum.prod(1),mask)),dtype=np.bool)\n",
    "        vTmix = v.T\n",
    "        vTmixN =((vTmix.T-vTmix.T.mean(0))/vTmix.T.std(0)).T\n",
    "        #ctb,KRd,betasv,v_T = fitmodels2(catd,v.T,eimum,t2s,tes,mmixN=vTmixN)\n",
    "        none,ctb,betasv,v_T = fitmodels_direct(catd,v.T,eimum,t2s,t2sG,tes,combmode,head,mmixN=vTmixN,full_sel=False)\n",
    "        ctb = ctb[ctb[:,0].argsort(),:]\n",
    "        ctb = np.vstack([ctb.T[0:3],sp]).T\n",
    "\n",
    "        #Save state\n",
    "        print(\"Saving PCA\")\n",
    "        pcastate = {'u':u,'s':s,'v':v,'ctb':ctb,'eigelb':eigelb,'spmin':spmin,'spcum':spcum}\n",
    "        try:\n",
    "            pcastate_f = gzip.open(pcastate_fn,'wb')\n",
    "            pickle.dump(pcastate,pcastate_f)\n",
    "            pcastate_f.close()\n",
    "        except:\n",
    "            print(\"Could not save PCA solution!\")\n",
    "\n",
    "    else:\n",
    "        print(\"Loading PCA\")\n",
    "        pcastate_f = gzip.open(pcastate_fn,'rb')\n",
    "        pcastate = pickle.load(pcastate_f)\n",
    "        (u, s, v, ctb,\n",
    "         eigelb, spmin, spcum) = (pcastate['u'], pcastate['s'], pcastate['v'],\n",
    "                                  pcastate['ctb'], pcastate['eigelb'],\n",
    "                                  pcastate['spmin'], pcastate['spcum'])\n",
    "\n",
    "    np.savetxt('comp_table_pca.txt',ctb[ctb[:,1].argsort(),:][::-1])\n",
    "    np.savetxt('mepca_mix.1D',v[ctb[:,1].argsort()[::-1],:].T)\n",
    "\n",
    "    kappas = ctb[ctb[:,1].argsort(),1]\n",
    "    rhos = ctb[ctb[:,2].argsort(),2]\n",
    "    fmin,fmid,fmax = getfbounds(ne)\n",
    "    kappa_thr = np.average(sorted([fmin,getelbow_mod(kappas,val=True)/2,fmid]),weights=[kdaw,1,1])\n",
    "    rho_thr = np.average(sorted([fmin,getelbow_cons(rhos,val=True)/2,fmid]),weights=[rdaw,1,1])\n",
    "    if int(kdaw)==-1:\n",
    "        kappas_lim = kappas[andb([kappas<fmid,kappas>fmin])==2]\n",
    "        #kappas_lim = kappas[andb([kappas<kappas[getelbow_mod(kappas)],kappas>fmin])==2]\n",
    "        kappa_thr = kappas_lim[getelbow_mod(kappas_lim)]\n",
    "        rhos_lim = rhos[andb([rhos<fmid,rhos>fmin])==2]\n",
    "        rho_thr = rhos_lim[getelbow_mod(rhos_lim)]\n",
    "        stabilize = True\n",
    "    if int(kdaw)!=-1 and int(rdaw)==-1:\n",
    "        rhos_lim = rhos[andb([rhos<fmid,rhos>fmin])==2]\n",
    "        rho_thr = rhos_lim[getelbow_mod(rhos_lim)]\n",
    "\n",
    "    temp1 = np.array(ctb[:, 1] > kappa_thr, dtype=np.int)\n",
    "    temp2 = np.array(ctb[:, 2] > rho_thr, dtype=np.int)\n",
    "    temp3 = np.array(ctb[:, 3] > eigelb, dtype=np.int)\n",
    "    temp4 = np.array(ctb[:, 3] > spmin, dtype=np.int)\n",
    "    temp5 = np.array(ctb[:, 1] != F_MAX, dtype=np.int)\n",
    "    temp6 = np.array(ctb[:, 2] != F_MAX, dtype=np.int)\n",
    "    pcscore = (temp1 + temp2 + temp3) * temp4 * temp5 * temp6\n",
    "    if stabilize:\n",
    "        temp7 = np.array(spcum < 0.95, dtype=np.int)\n",
    "        temp8 = np.array(ctb[:, 2] > fmin, dtype=np.int)\n",
    "        temp9 = np.array(ctb[:, 1] > fmin, dtype=np.int)\n",
    "        pcscore = pcscore * temp7 * temp8 * temp9\n",
    "\n",
    "    pcsel = pcscore > 0\n",
    "    pcrej = np.array(pcscore==0,dtype=np.int)*np.array(ctb[:,3]>spmin,dtype=np.int) > 0\n",
    "\n",
    "    dd = u.dot(np.diag(s*np.array(pcsel,dtype=np.int))).dot(v)\n",
    "\n",
    "    #if wvpca:\n",
    "    #   print \"++Transforming PCA solution from wavelet domain to time domain\"\n",
    "    #   dd = idwtmat(dd,cAl)\n",
    "\n",
    "    nc = s[pcsel].shape[0]\n",
    "    print(pcsel)\n",
    "    print(\"--Selected %i components. Minimum Kappa=%0.2f Rho=%0.2f\" % (nc,kappa_thr,rho_thr))\n",
    "\n",
    "    dd = ((dd.T-dd.T.mean(0))/dd.T.std(0)).T  # Variance normalize timeseries\n",
    "    dd = (dd-dd.mean())/dd.std()  # Variance normalize everything\n",
    "\n",
    "    return nc,dd\n",
    "\n",
    "\n",
    "def tedica(nc, dd, conv, fixed_seed, cost, final_cost):\n",
    "    \"\"\"\n",
    "    Input is dimensionally reduced spatially concatenated multi-echo time series dataset from tedpca()\n",
    "    Output is comptable, mmix, smaps from ICA, and betas from fitting catd to mmix\n",
    "    \"\"\"\n",
    "    #Do ICA\n",
    "    import mdp\n",
    "    climit = float(\"%s\" % conv)\n",
    "    #icanode = mdp.nodes.FastICANode(white_comp=nc, white_parm={'svd':True},approach='symm', g=cost, fine_g=options.finalcost, limit=climit, verbose=True)\n",
    "    mdp.numx_rand.seed(fixed_seed)\n",
    "    icanode = mdp.nodes.FastICANode(white_comp=nc,approach='symm', g=cost, fine_g=final_cost, coarse_limit=climit*100, limit=climit, verbose=True)\n",
    "    icanode.train(dd)\n",
    "    smaps = icanode.execute(dd)\n",
    "    mmix = icanode.get_recmatrix().T\n",
    "    mmix = (mmix-mmix.mean(0))/mmix.std(0)\n",
    "    return mmix\n",
    "\n",
    "\n",
    "def gscontrol_raw(OCcatd,head,dtrank=4):\n",
    "    \"\"\"\n",
    "    This function uses the spatial global signal estimation approach to modify catd (global variable) to\n",
    "    removal global signal out of individual echo time series datasets. The spatial global signal is estimated\n",
    "    from the optimally combined data after detrending with a Legendre polynomial basis of order=0 and degree=dtrank.\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"++ Applying amplitude-based T1 equilibration correction\")\n",
    "\n",
    "    #Legendre polynomial basis for denoising\n",
    "    from scipy.special import lpmv\n",
    "    Lmix = np.array([lpmv(0,vv,np.linspace(-1,1,OCcatd.shape[-1])) for vv in range(dtrank)]).T\n",
    "\n",
    "    #Compute mean, std, mask local to this function - inefficient, but makes this function a bit more modular\n",
    "    Gmu = OCcatd.mean(-1)\n",
    "    Gstd = OCcatd.std(-1)\n",
    "    Gmask = Gmu!=0\n",
    "\n",
    "    #Find spatial global signal\n",
    "    dat = OCcatd[Gmask] - Gmu[Gmask][:,np.newaxis]\n",
    "    sol = np.linalg.lstsq(Lmix,dat.T) #Legendre basis for detrending\n",
    "    detr = dat - np.dot(sol[0].T,Lmix.T)[0]\n",
    "    sphis = (detr).min(1)\n",
    "    sphis -= sphis.mean()\n",
    "    niwrite(unmask(sphis,Gmask),aff,'T1gs.nii',head)\n",
    "\n",
    "    #Find time course of the spatial global signal, make basis with the Legendre basis\n",
    "    glsig = np.linalg.lstsq(np.atleast_2d(sphis).T,dat)[0]\n",
    "    glsig = (glsig-glsig.mean() ) / glsig.std()\n",
    "    np.savetxt('glsig.1D',glsig)\n",
    "    glbase = np.hstack([Lmix,glsig.T])\n",
    "\n",
    "    #Project global signal out of optimally combined data\n",
    "    sol = np.linalg.lstsq(np.atleast_2d(glbase),dat.T)\n",
    "    tsoc_nogs = dat - np.dot(np.atleast_2d(sol[0][dtrank]).T,np.atleast_2d(glbase.T[dtrank])) + Gmu[Gmask][:,np.newaxis]\n",
    "\n",
    "    # global OCcatd, sphis_raw\n",
    "    sphis_raw = sphis\n",
    "    niwrite(OCcatd,aff,'tsoc_orig.nii',head)\n",
    "    OCcatd = unmask(tsoc_nogs,Gmask)\n",
    "    niwrite(OCcatd,aff,'tsoc_nogs.nii',head)\n",
    "\n",
    "    #Project glbase out of each echo\n",
    "    # for ii in range(Ne):\n",
    "    #     dat = catd[:,:,:,ii,:][Gmask]\n",
    "    #     sol = np.linalg.lstsq(np.atleast_2d(glbase),dat.T)\n",
    "    #     e_nogs = dat - np.dot(np.atleast_2d(sol[0][dtrank]).T,np.atleast_2d(glbase.T[dtrank]))\n",
    "    #     catd[:,:,:,ii,:] = unmask(e_nogs,Gmask)\n",
    "\n",
    "\n",
    "def gscontrol_mmix(mmix, acc, rej, midk, empty, head):\n",
    "\n",
    "    Gmu = OCcatd.mean(-1)\n",
    "    Gstd = OCcatd.std(-1)\n",
    "    Gmask = Gmu!=0\n",
    "\n",
    "    \"\"\"\n",
    "    Compute temporal regression\n",
    "    \"\"\"\n",
    "    dat = (OCcatd[Gmask] - Gmu[Gmask][:,np.newaxis]) / Gstd[mask][:,np.newaxis]\n",
    "    solG = np.linalg.lstsq(mmix,dat.T)\n",
    "    resid = dat - np.dot(solG[0].T,mmix.T)\n",
    "\n",
    "    \"\"\"\n",
    "    Build BOLD time series without amplitudes, and save T1-like effect\n",
    "    \"\"\"\n",
    "    bold_ts = np.dot(solG[0].T[:,acc],mmix[:,acc].T)\n",
    "    sphis = bold_ts.min(-1)\n",
    "    sphis -= sphis.mean()\n",
    "    print(sphis.shape)\n",
    "    niwrite(unmask(sphis,mask),aff,'sphis_hik.nii',head)\n",
    "\n",
    "    \"\"\"\n",
    "    Find the global signal based on the T1-like effect\n",
    "    \"\"\"\n",
    "    sol = np.linalg.lstsq(np.atleast_2d(sphis).T,dat)\n",
    "    glsig = sol[0]\n",
    "\n",
    "    \"\"\"\n",
    "    T1 correct time series by regression\n",
    "    \"\"\"\n",
    "    bold_noT1gs = bold_ts - np.dot(np.linalg.lstsq(glsig.T,bold_ts.T)[0].T,glsig)\n",
    "    niwrite(unmask(bold_noT1gs*Gstd[mask][:,np.newaxis],mask),aff,'hik_ts_OC_T1c.nii',head)\n",
    "\n",
    "    \"\"\"\n",
    "    Make medn version of T1 corrected time series\n",
    "    \"\"\"\n",
    "    niwrite(Gmu[:,:,:,np.newaxis]+unmask((bold_noT1gs+resid)*Gstd[mask][:,np.newaxis] ,mask),aff,'dn_ts_OC_T1c.nii',head)\n",
    "\n",
    "    \"\"\"\n",
    "    Orthogonalize mixing matrix w.r.t. T1-GS\n",
    "    \"\"\"\n",
    "    mmixnogs = mmix.T - np.dot(np.linalg.lstsq(glsig.T,mmix)[0].T,glsig)\n",
    "    mmixnogs_mu = mmixnogs.mean(-1)\n",
    "    mmixnogs_std = mmixnogs.std(-1)\n",
    "    mmixnogs_norm = (mmixnogs-mmixnogs_mu[:,np.newaxis])/mmixnogs_std[:,np.newaxis]\n",
    "    mmixnogs_norm = np.vstack([np.atleast_2d(np.ones(max(glsig.shape))),glsig,mmixnogs_norm])\n",
    "\n",
    "    \"\"\"\n",
    "    Write T1-GS corrected components and mixing matrix\n",
    "    \"\"\"\n",
    "    sol = np.linalg.lstsq(mmixnogs_norm.T,dat.T)\n",
    "    niwrite(unmask(sol[0].T[:,2:],mask),aff,'betas_hik_OC_T1c.nii',head)\n",
    "    np.savetxt('meica_mix_T1c.1D',mmixnogs)\n",
    "\n",
    "\n",
    "def write_split_ts(data,comptable,mmix, acc, rej, midk, head,suffix=''):\n",
    "    mdata = fmask(data,mask)\n",
    "    betas = fmask(get_coeffs(unmask((mdata.T-mdata.T.mean(0)).T,mask),mask,mmix),mask)\n",
    "    dmdata = mdata.T-mdata.T.mean(0)\n",
    "    varexpl = (1-((dmdata.T-betas.dot(mmix.T))**2.).sum()/(dmdata**2.).sum())*100\n",
    "    print('Variance explained: ', varexpl , '%')\n",
    "    midkts = betas[:,midk].dot(mmix.T[midk,:])\n",
    "    lowkts = betas[:,rej].dot(mmix.T[rej,:])\n",
    "    if len(acc)!=0:\n",
    "        niwrite(unmask(betas[:,acc].dot(mmix.T[acc,:]),mask),aff,'_'.join(['hik_ts',suffix])+'.nii',head)\n",
    "    if len(midk)!=0:\n",
    "        niwrite(unmask(midkts,mask),aff,'_'.join(['midk_ts',suffix])+'.nii',head)\n",
    "    if len(rej)!=0:\n",
    "        niwrite(unmask(lowkts,mask),aff,'_'.join(['lowk_ts',suffix])+'.nii',head)\n",
    "    niwrite(unmask(fmask(data,mask)-lowkts-midkts,mask),aff,'_'.join(['dn_ts',suffix])+'.nii',head)\n",
    "    return varexpl\n",
    "\n",
    "\n",
    "def writefeats(data,mmix,mask,head,suffix=''):\n",
    "    #Write feature versions of components\n",
    "    feats = computefeats2(data,mmix,mask)\n",
    "    niwrite(unmask(feats,mask),aff,'_'.join(['feats',suffix])+'.nii',head)\n",
    "\n",
    "\n",
    "def writect(comptable, nt, acc, rej, midk, empty, ctname='', varexpl='-1'):\n",
    "    nc = comptable.shape[0]\n",
    "    sortab = comptable[comptable[:,1].argsort()[::-1],:]\n",
    "    if ctname=='': ctname = 'comp_table.txt'\n",
    "    open('accepted.txt','w').write(','.join([str(int(cc)) for cc in acc]))\n",
    "    open('rejected.txt','w').write(','.join([str(int(cc)) for cc in rej]))\n",
    "    open('midk_rejected.txt','w').write(','.join([str(int(cc)) for cc in midk]))\n",
    "    with open(ctname,'w') as f:\n",
    "        f.write(\"#\\n#ME-ICA Component statistics table for: %s #\\n\" % (os.path.abspath(os.path.curdir)) )\n",
    "        f.write(\"#Dataset variance explained by ICA (VEx): %.02f \\n\" %  ( varexpl ) )\n",
    "        f.write(\"#Total components generated by decomposition (TCo): %i \\n\" %  ( nc ) )\n",
    "        f.write(\"#No. accepted BOLD-like components, i.e. effective degrees of freedom for correlation (lower bound; DFe): %i\\n\" %  ( len(acc) ) )\n",
    "        f.write(\"#Total number of rejected components (RJn): %i\\n\" %  (len(midk)+len(rej)) )\n",
    "        f.write(\"#Nominal degress of freedom in denoised time series (..._medn.nii.gz; DFn): %i \\n\" %  (nt-len(midk)-len(rej)) )\n",
    "        f.write(\"#ACC %s \\t#Accepted BOLD-like components\\n\" % ','.join([str(int(cc)) for cc in acc]) )\n",
    "        f.write(\"#REJ %s \\t#Rejected non-BOLD components\\n\" % ','.join([str(int(cc)) for cc in rej]) )\n",
    "        f.write(\"#MID %s \\t#Rejected R2*-weighted artifacts\\n\" % ','.join([str(int(cc)) for cc in midk]) )\n",
    "        f.write(\"#IGN %s \\t#Ignored components (kept in denoised time series)\\n\" % ','.join([str(int(cc)) for cc in empty]) )\n",
    "        f.write(\"#VEx   TCo DFe RJn DFn \\n\")\n",
    "        f.write(\"##%.02f    %i  %i  %i  %i \\n\" % (varexpl,nc,len(acc),len(midk)+len(rej),nt-len(midk)-len(rej)))\n",
    "        f.write(\"#  comp    Kappa   Rho %%Var   %%Var(norm) \\n\")\n",
    "        for i in range(nc):\n",
    "            f.write('%d\\t%f\\t%f\\t%.2f\\t%.2f\\n'%(sortab[i,0],sortab[i,1],sortab[i,2],sortab[i,3],sortab[i,4]))\n",
    "\n",
    "\n",
    "def writeresults(OCcatd, comptable, mmix, nt, acc, rej, midk, empty, head):\n",
    "    print(\"++ Writing optimally combined time series\")\n",
    "    ts = OCcatd\n",
    "    niwrite(ts,aff,'ts_OC.nii',head)\n",
    "    print(\"++ Writing Kappa-filtered optimally combined timeseries\")\n",
    "    varexpl = write_split_ts(ts,comptable,mmix,acc, rej, midk, head, suffix = 'OC')\n",
    "    print(\"++ Writing signal versions of components\")\n",
    "    ts_B = get_coeffs(ts,mask,mmix)\n",
    "    niwrite(ts_B[:,:,:,:],aff,'_'.join(['betas','OC'])+'.nii', head)\n",
    "    if len(acc)!=0:\n",
    "        niwrite(ts_B[:,:,:,acc],aff,'_'.join(['betas_hik','OC'])+'.nii', head)\n",
    "        print(\"++ Writing optimally combined high-Kappa features\")\n",
    "        writefeats(split_ts(ts,comptable,mmix,acc, rej, midk)[0],mmix[:,acc],mask,head, suffix = 'OC2')\n",
    "    print(\"++ Writing component table\")\n",
    "    writect(comptable, nt, acc, rej, midk, empty, ctname='comp_table.txt',varexpl=varexpl)\n",
    "\n",
    "\n",
    "def writeresults_echoes(acc, rej, midk, head):\n",
    "    for ii in range(ne):\n",
    "        print(\"++ Writing Kappa-filtered TE#%i timeseries\" % (ii+1))\n",
    "        write_split_ts(catd[:,:,:,ii,:],comptable, mmix,acc, rej, midk, head, suffix = 'e%i' % (ii+1))\n",
    "\n",
    "\n",
    "def main(options):\n",
    "    \"\"\"\n",
    "\n",
    "    Args (and defaults):\n",
    "    data, tes, mixm=None, ctab=None, manacc=None, strict=False,\n",
    "             no_gscontrol=False, kdaw=10., rdaw=1., conv=2.5e-5, ste=-1,\n",
    "             combmode='t2s', dne=False, initcost='tanh', finalcost='tanh',\n",
    "             stabilize=False, fout=False, filecsdata=False, label=None,\n",
    "             fixed_seed=42\n",
    "    \"\"\"\n",
    "    global tes, ne, catd, head, aff\n",
    "    tes = [float(te) for te in options.tes]\n",
    "    ne = len(tes)\n",
    "    catim  = nib.load(options.data[0])\n",
    "\n",
    "    head = catim.get_header()\n",
    "    head.extensions = []\n",
    "    head.set_sform(head.get_sform(),code=1)\n",
    "    aff = catim.get_affine()\n",
    "    catd = cat2echos(catim.get_data(),ne)\n",
    "    nx,ny,nz,Ne,nt = catd.shape\n",
    "\n",
    "    #Parse options, prepare output directory\n",
    "    if options.fout: options.fout = aff\n",
    "    else: options.fout=None\n",
    "\n",
    "    global kdaw, rdaw\n",
    "    if not options.stabilize:\n",
    "        stabilize = False\n",
    "    else:\n",
    "        stabilize = True\n",
    "    kdaw = float(options.kdaw)\n",
    "    rdaw = float(options.rdaw)\n",
    "\n",
    "    if options.label!=None: dirname='%s' % '.'.join(['TED',options.label])\n",
    "    else: dirname='TED'\n",
    "    os.system('mkdir %s' % dirname)\n",
    "    if options.mixm!=None:\n",
    "        try: os.system('cp %s %s/meica_mix.1D; cp %s %s/%s' % (options.mixm,dirname,options.mixm,dirname,os.path.basename(options.mixm)))\n",
    "        except: pass\n",
    "    if options.ctab!=None:\n",
    "        try: os.system('cp %s %s/comp_table.txt; cp %s %s/%s' % (options.mixm,dirname,options.mixm,dirname,os.path.basename(options.mixm)))\n",
    "        except: pass\n",
    "\n",
    "    os.chdir(dirname)\n",
    "\n",
    "    print(\"++ Computing Mask\")\n",
    "    global mask\n",
    "    mask,masksum = makeadmask(catd,minimum=False,getsum=True)\n",
    "\n",
    "    print(\"++ Computing T2* map\")\n",
    "    global t2s, s0, t2ss, s0s, t2sG, s0G\n",
    "    t2s,s0,t2ss,s0s,t2sG,s0G = t2sadmap(catd,mask,tes,masksum,1)\n",
    "\n",
    "    #Condition values\n",
    "    cap_t2s = stats.scoreatpercentile(t2s.flatten(),99.5, interpolation_method='lower')\n",
    "    t2s[t2s>cap_t2s*10]=cap_t2s\n",
    "    niwrite(s0,aff,'s0v.nii',head)\n",
    "    niwrite(t2s,aff,'t2sv.nii',head)\n",
    "    niwrite(t2ss,aff,'t2ss.nii',head)\n",
    "    niwrite(s0s,aff,'s0vs.nii',head)\n",
    "    niwrite(s0G,aff,'s0vG.nii',head)\n",
    "    niwrite(t2sG,aff,'t2svG.nii',head)\n",
    "\n",
    "    #Optimally combine data\n",
    "    combmode = options.combmode\n",
    "    global OCcatd\n",
    "    OCcatd = optcom(catd,\n",
    "                    t2sG,\n",
    "                    tes,\n",
    "                    mask,\n",
    "                    combmode,\n",
    "                    useG=True)\n",
    "\n",
    "    if not options.no_gscontrol:\n",
    "        gscontrol_raw(OCcatd, head)\n",
    "\n",
    "    if options.mixm == None:\n",
    "        print(\"++ Doing ME-PCA and ME-ICA\")\n",
    "\n",
    "        nc,dd = tedpca(combmode, mask, stabilize, head, ste = options.ste)\n",
    "\n",
    "        mmix_orig = tedica(nc, dd, options.conv,  options.fixed_seed, cost=options.initcost, final_cost = options.finalcost)\n",
    "        np.savetxt('__meica_mix.1D',mmix_orig)\n",
    "        seldict,comptable,betas,mmix = fitmodels_direct(catd,mmix_orig,mask,t2s,t2sG,tes,combmode,head, fout=options.fout,reindex=True)\n",
    "\n",
    "        np.savetxt('meica_mix.1D',mmix)\n",
    "        if 'GROUP0' in sys.argv:\n",
    "            group0_flag = True\n",
    "        else: group0_flag = False\n",
    "        acc,rej,midk,empty = selcomps(seldict,mmix,head, knobargs=options,group0_only=group0_flag,strict_mode=options.strict)\n",
    "        del dd\n",
    "    else:\n",
    "        mmix_orig = np.loadtxt('meica_mix.1D')\n",
    "        eim = eimask(np.float64(fmask(catd,mask)))==1\n",
    "        eimum = np.array(np.squeeze(unmask(np.array(eim,dtype=np.int).prod(1),mask)),dtype=np.bool)\n",
    "        seldict,comptable,betas,mmix = fitmodels_direct(catd,mmix_orig,mask,t2s,t2sG,tes,combmode,head,fout=options.fout)\n",
    "        if options.ctab == None:\n",
    "            acc,rej,midk,empty = selcomps(seldict,mmix,head, knobargs=options,strict_mode=options.strict)\n",
    "        else:\n",
    "            acc,rej,midk,empty = ctabsel(ctabfile)\n",
    "\n",
    "    if len(acc)==0:\n",
    "        print(\"\\n** WARNING! No BOLD components detected!!! Please check data and results!\\n\")\n",
    "\n",
    "    writeresults(OCcatd, comptable, mmix, nt, acc, rej, midk, empty, head)\n",
    "    gscontrol_mmix(mmix, acc, rej, midk, empty, head)\n",
    "    if options.dne: writeresults_echoes(acc, rej, midk, head)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_perturb(starting_triu, epsi,mmix_orig, nc):\n",
    "    starting_m = np.zeros((nc,nc))\n",
    "    starting_m[np.triu_indices(nc)] = starting_triu\n",
    "    skew_sym = (starting_m -  starting_m.T) * epsi\n",
    "    perturb = expm(skew_sym)\n",
    "    rr = {}\n",
    "    mmix = np.dot(mmix_orig.copy(),perturb)\n",
    "    rr['kappas'],rr['rhos']= get_kappas_rhos(catd,catd_uncatted,catd_uncatted_masked, mmix, mask, mask_tile,t2s, t2sG, tes,combmode, head, tsoc, tsoc_unmask, tsoc_mean, tsoc_dm, tsoc_dm_unmask,tsoc_dm_unmask_for_gc, fout=options.fout,reindex=True)\n",
    "    rr['mmix'] = mmix\n",
    "    rr['score'] = get_score(rr['kappas'],rr['rhos'])\n",
    "    return rr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tsoc(catd, t2sG, tes, mask, combmode):\n",
    "    tsoc = np.array(optcom(catd, t2sG, tes,\n",
    "                           mask, combmode, useG=True),\n",
    "                    dtype=float)[mask]\n",
    "    tsoc_mean = tsoc.mean(axis=-1)\n",
    "    tsoc_dm = tsoc-tsoc_mean[:,np.newaxis]\n",
    "    return tsoc, tsoc_mean, tsoc_dm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit\n",
    "def get_coeffs(data, mask, X, mdata = None,  add_const=False):\n",
    "    \"\"\"\n",
    "    get_coeffs(data,X)\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : array-like\n",
    "        Array of shape (nx, ny, nz, nt)\n",
    "    mask : array-like\n",
    "        Array of shape (nx, ny, nz)\n",
    "    X : array-like\n",
    "        Array of shape (nt, nc)\n",
    "    add_const : bool, optional\n",
    "        Default is False.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    out : array_like\n",
    "        Array of shape (nx, ny, nz, nc)\n",
    "    \"\"\"\n",
    "    if mdata is None:\n",
    "        mdata = fmask(data, mask).transpose()\n",
    "\n",
    "    # Coerce X to >=2d\n",
    "    X = np.atleast_2d(X)\n",
    "\n",
    "    if X.shape[0] == 1:\n",
    "        X = X.T\n",
    "    Xones = np.atleast_2d(np.ones(np.min(mdata.shape))).T\n",
    "    if add_const:\n",
    "        X = np.hstack([X, Xones])\n",
    "\n",
    "    tmpbetas = np.linalg.lstsq(X, mdata)[0].transpose()\n",
    "    if add_const:\n",
    "        tmpbetas = tmpbetas[:, :-1]\n",
    "    out = unmask(tmpbetas, mask)\n",
    "\n",
    "    return out\n",
    "\n",
    "@jit\n",
    "def cat2echos(data, Ne):\n",
    "    \"\"\"\n",
    "    Separates z- and echo-axis in `data`\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : array_like\n",
    "        Array of shape (nx, ny, nz*Ne, nt)\n",
    "    Ne : int\n",
    "        Number of echoes that were in original (uncombined) data array\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    ndarray\n",
    "        Array of shape (nx, ny, nz, Ne, nt)\n",
    "    \"\"\"\n",
    "\n",
    "    nx, ny = data.shape[0:2]\n",
    "    nz = data.shape[2] // Ne\n",
    "    if len(data.shape) > 3:\n",
    "        nt = data.shape[3]\n",
    "    else:\n",
    "        nt = 1\n",
    "    return np.reshape(data, (nx, ny, nz, Ne, nt), order='F')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_kappas_rhos(catd, catd_uncatted,catd_uncatted_masked, mmix, mask, mask_tile,\n",
    "                     t2s, t2sG, tes,\n",
    "                     combmode, head, \n",
    "                     tsoc, tsoc_unmask ,tsoc_mean, \n",
    "                     tsoc_dm,tsoc_dm_unmask,tsoc_dm_unmask_for_gc,\n",
    "                     fout=None,\n",
    "                     reindex=False,mmixN=None,\n",
    "                     full_sel=True):\n",
    "    \"\"\"\n",
    "    Usage:\n",
    "\n",
    "    fitmodels_direct(fout)\n",
    "\n",
    "    Input:\n",
    "    fout is flag for output of per-component TE-dependence maps\n",
    "    t2s is a (nx,ny,nz) ndarray\n",
    "    tes is a 1d array\n",
    "    \"\"\"\n",
    "    #Compute un-normalized weight dataset (features)\n",
    "    if mmixN is None:\n",
    "        mmixN = mmix\n",
    "    #WTS = computefeats2(unmask(unmask(tsoc,mask)[t2s!=0],t2s!=0),mmixN,t2s!=0,normalize=False)\n",
    "    WTS = computefeats2(tsoc_unmask,mmixN,mask,normalize=False)\n",
    "\n",
    "    #Compute PSC dataset - shouldn't have to refit data\n",
    "    global tsoc_B\n",
    "    tsoc_B = get_coeffs(tsoc_dm_unmask, mask,mmix, mdata = tsoc_dm_unmask_for_gc)[mask]\n",
    "    tsoc_Babs = np.abs(tsoc_B)\n",
    "    PSC = tsoc_B/tsoc.mean(axis=-1)[:,np.newaxis]*100\n",
    "\n",
    "    #Compute skews to determine signs based on unnormalized weights, correct mmix & WTS signs based on spatial distribution tails\n",
    "    from scipy.stats import skew\n",
    "    signs = skew(WTS,axis=0)\n",
    "    signs /= np.abs(signs)\n",
    "    mmix = mmix.copy()\n",
    "    mmix*=signs\n",
    "    WTS*=signs\n",
    "    PSC*=signs\n",
    "    totvar = (tsoc_B**2).sum()\n",
    "    totvar_norm = (WTS**2).sum()\n",
    "\n",
    "    #Compute Betas and means over TEs for TE-dependence analysis\n",
    "    Ne = len(tes)\n",
    "    betas = cat2echos(get_coeffs(catd_uncatted,mask_tile,mmix, mdata = catd_uncatted_masked),Ne)\n",
    "    nx,ny,nz,Ne,nc = betas.shape\n",
    "    Nm = mask.sum()\n",
    "    NmD = (t2s!=0).sum()\n",
    "    mu = catd.mean(axis=-1)\n",
    "    tes = np.reshape(tes,(Ne,1))\n",
    "    fmin,fmid,fmax = getfbounds(Ne)\n",
    "\n",
    "    #Mask arrays\n",
    "    mumask   = fmask(mu,t2s!=0)\n",
    "    #t2smask  = fmask(t2s,mask)\n",
    "    t2smask  = fmask(t2s,t2s!=0)\n",
    "    betamask = fmask(betas,t2s!=0)\n",
    "\n",
    "    #Setup Xmats\n",
    "    #Model 1\n",
    "    X1 = mumask.transpose()\n",
    "\n",
    "    #Model 2\n",
    "    X2 = np.tile(tes,(1,NmD))*mumask.transpose()/t2smask.transpose()\n",
    "\n",
    "    #Tables for component selection\n",
    "    global Kappas, Rhos, varex, varex_norm\n",
    "    global Z_maps, F_R2_maps, F_S0_maps\n",
    "    global Z_clmaps, F_R2_clmaps, F_S0_clmaps\n",
    "    global Br_clmaps_R2, Br_clmaps_S0\n",
    "    Kappas = np.zeros([nc])\n",
    "    Rhos = np.zeros([nc])\n",
    "    varex = np.zeros([nc])\n",
    "    varex_norm = np.zeros([nc])\n",
    "    Z_maps = np.zeros([Nm,nc])\n",
    "    F_R2_maps = np.zeros([NmD,nc])\n",
    "    F_S0_maps = np.zeros([NmD,nc])\n",
    "    Z_clmaps = np.zeros([Nm,nc])\n",
    "    F_R2_clmaps = np.zeros([NmD,nc])\n",
    "    F_S0_clmaps = np.zeros([NmD,nc])\n",
    "    Br_clmaps_R2 = np.zeros([Nm,nc])\n",
    "    Br_clmaps_S0 = np.zeros([Nm,nc])\n",
    "    \n",
    "    WTS_unmask = unmask(WTS,mask)\n",
    "    for i in range(nc):\n",
    "\n",
    "        #size of B is (nc, nx*ny*nz)\n",
    "        B = np.atleast_3d(betamask)[:,:,i].transpose()\n",
    "        alpha = (np.abs(B)**2).sum(axis=0)\n",
    "        varex[i] = (tsoc_B[:,i]**2).sum()/totvar*100.\n",
    "        varex_norm[i] = (WTS_unmask[t2s!=0][:,i]**2).sum()/totvar_norm*100.\n",
    "\n",
    "        #S0 Model\n",
    "        coeffs_S0 = (B*X1).sum(axis=0)/(X1**2).sum(axis=0)\n",
    "        SSE_S0 = (B - X1*np.tile(coeffs_S0,(Ne,1)))**2\n",
    "        SSE_S0 = SSE_S0.sum(axis=0)\n",
    "        F_S0 = (alpha - SSE_S0)*2/(SSE_S0)\n",
    "        F_S0_maps[:,i] = F_S0\n",
    "\n",
    "        #R2 Model\n",
    "        coeffs_R2 = (B*X2).sum(axis=0)/(X2**2).sum(axis=0)\n",
    "        SSE_R2 = (B - X2*np.tile(coeffs_R2,(Ne,1)))**2\n",
    "        SSE_R2 = SSE_R2.sum(axis=0)\n",
    "        F_R2 = (alpha - SSE_R2)*2/(SSE_R2)\n",
    "        F_R2_maps[:,i] = F_R2\n",
    "\n",
    "        #Compute weights as Z-values\n",
    "        wtsZ=(WTS[:,i]-WTS[:,i].mean())/WTS[:,i].std()\n",
    "        wtsZ[np.abs(wtsZ)>Z_MAX]=(Z_MAX*(np.abs(wtsZ)/wtsZ))[np.abs(wtsZ)>Z_MAX]\n",
    "        Z_maps[:,i] = wtsZ\n",
    "\n",
    "        #Compute Kappa and Rho\n",
    "        F_S0[F_S0>F_MAX] = F_MAX\n",
    "        F_R2[F_R2>F_MAX] = F_MAX\n",
    "        Kappas[i] = np.average(F_R2,weights=np.abs(np.squeeze(unmask(wtsZ,mask)[t2s!=0]**2.)))\n",
    "        Rhos[i] = np.average(F_S0,weights=np.abs(np.squeeze(unmask(wtsZ,mask)[t2s!=0]**2.)))\n",
    "    \n",
    "    return Kappas, Rhos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_score(Kappas, Rhos):\n",
    "    return(-1*(Kappas.sum() + np.abs(Kappas - Rhos).sum() + Rhos.sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/venv/lib/python3.6/site-packages/ipykernel_launcher.py:12: DeprecationWarning: get_header method is deprecated.\n",
      "Please use the ``img.header`` property instead.\n",
      "\n",
      "* deprecated from version: 2.1\n",
      "* Will raise <class 'nibabel.deprecator.ExpiredDeprecationError'> as of version: 4.0\n",
      "  if sys.path[0] == '':\n",
      "/opt/conda/envs/venv/lib/python3.6/site-packages/ipykernel_launcher.py:15: DeprecationWarning: get_affine method is deprecated.\n",
      "Please use the ``img.affine`` property instead.\n",
      "\n",
      "* deprecated from version: 2.1\n",
      "* Will raise <class 'nibabel.deprecator.ExpiredDeprecationError'> as of version: 4.0\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++ Computing Mask\n",
      "++ Computing T2* map\n",
      "Out shape is  (42, 56, 38, 256)\n",
      "++ Applying amplitude-based T1 equilibration correction\n",
      "++ Doing ME-PCA and ME-ICA\n",
      "-Computing PCA of optimally combined multi-echo data\n",
      "0\n",
      "30.9163897521 154581.94876\n",
      "Loading PCA\n",
      "[ True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False]\n",
      "--Selected 130 components. Minimum Kappa=9.00 Rho=9.35\n"
     ]
    }
   ],
   "source": [
    "# Set the data input path here\n",
    "input_path = '/perturb/data/zcat_ffd.nii.gz'\n",
    "parser = run.get_parser()\n",
    "options = parser.parse_args(['-d', input_path,\n",
    "                                 '-e', '14.5', '38.5', '62.5'])\n",
    "\n",
    "global tes, ne, catd, head, aff\n",
    "tes = [float(te) for te in options.tes]\n",
    "ne = len(tes)\n",
    "catim  = nib.load(options.data[0])\n",
    "\n",
    "head = catim.get_header()\n",
    "head.extensions = []\n",
    "head.set_sform(head.get_sform(),code=1)\n",
    "aff = catim.get_affine()\n",
    "catd = cat2echos(catim.get_data(),ne)\n",
    "nx,ny,nz,Ne,nt = catd.shape\n",
    "\n",
    "#Parse options, prepare output directory\n",
    "if options.fout: options.fout = aff\n",
    "else: options.fout=None\n",
    "\n",
    "global kdaw, rdaw\n",
    "if not options.stabilize:\n",
    "    stabilize = False\n",
    "else:\n",
    "    stabilize = True\n",
    "kdaw = float(options.kdaw)\n",
    "rdaw = float(options.rdaw)\n",
    "\n",
    "if options.label!=None: dirname='%s' % '.'.join(['TED',options.label])\n",
    "else: dirname='TED'\n",
    "os.system('mkdir %s' % dirname)\n",
    "if options.mixm!=None:\n",
    "    try: os.system('cp %s %s/meica_mix.1D; cp %s %s/%s' % (options.mixm,dirname,options.mixm,dirname,os.path.basename(options.mixm)))\n",
    "    except: pass\n",
    "if options.ctab!=None:\n",
    "    try: os.system('cp %s %s/comp_table.txt; cp %s %s/%s' % (options.mixm,dirname,options.mixm,dirname,os.path.basename(options.mixm)))\n",
    "    except: pass\n",
    "\n",
    "os.chdir(dirname)\n",
    "\n",
    "print(\"++ Computing Mask\")\n",
    "global mask\n",
    "mask,masksum = makeadmask(catd,minimum=False,getsum=True)\n",
    "\n",
    "print(\"++ Computing T2* map\")\n",
    "global t2s, s0, t2ss, s0s, t2sG, s0G\n",
    "t2s,s0,t2ss,s0s,t2sG,s0G = t2sadmap(catd,mask,tes,masksum,1)\n",
    "\n",
    "#Condition values\n",
    "cap_t2s = stats.scoreatpercentile(t2s.flatten(),99.5, interpolation_method='lower')\n",
    "t2s[t2s>cap_t2s*10]=cap_t2s\n",
    "niwrite(s0,aff,'s0v.nii',head)\n",
    "niwrite(t2s,aff,'t2sv.nii',head)\n",
    "niwrite(t2ss,aff,'t2ss.nii',head)\n",
    "niwrite(s0s,aff,'s0vs.nii',head)\n",
    "niwrite(s0G,aff,'s0vG.nii',head)\n",
    "niwrite(t2sG,aff,'t2svG.nii',head)\n",
    "\n",
    "#Optimally combine data\n",
    "combmode = options.combmode\n",
    "global OCcatd\n",
    "OCcatd = optcom(catd,\n",
    "                t2sG,\n",
    "                tes,\n",
    "                mask,\n",
    "                combmode,\n",
    "                useG=True)\n",
    "\n",
    "if not options.no_gscontrol:\n",
    "    gscontrol_raw(OCcatd, head)\n",
    "\n",
    "if options.mixm == None:\n",
    "    print(\"++ Doing ME-PCA and ME-ICA\")\n",
    "\n",
    "    nc,dd = tedpca(combmode, mask, stabilize, head, ste = options.ste)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step no. 1, convergence: 1.0000000\n",
      "Step no. 2, convergence: 0.2220568\n",
      "Step no. 3, convergence: 0.2740738\n",
      "Step no. 4, convergence: 0.3719902\n",
      "Step no. 5, convergence: 0.4765292\n",
      "Step no. 6, convergence: 0.6944490\n",
      "Step no. 7, convergence: 0.9392614\n",
      "Step no. 8, convergence: 0.5150565\n",
      "Step no. 9, convergence: 0.2847168\n",
      "Step no. 10, convergence: 0.3276061\n",
      "Step no. 11, convergence: 0.3615473\n",
      "Step no. 12, convergence: 0.4307660\n",
      "Step no. 13, convergence: 0.5252906\n",
      "Step no. 14, convergence: 0.6980981\n",
      "Step no. 15, convergence: 0.9923410\n",
      "Step no. 16, convergence: 0.4788351\n",
      "Step no. 17, convergence: 0.0824193\n",
      "Step no. 18, convergence: 0.0067446\n",
      "Step no. 19, convergence: 0.0055341\n",
      "Step no. 20, convergence: 0.0039695\n",
      "Step no. 21, convergence: 0.0042684\n",
      "Step no. 22, convergence: 0.0042674\n",
      "Step no. 23, convergence: 0.0038004\n",
      "Step no. 24, convergence: 0.0031997\n",
      "Step no. 25, convergence: 0.0031598\n",
      "Step no. 26, convergence: 0.0029874\n",
      "Step no. 27, convergence: 0.0027491\n",
      "Step no. 28, convergence: 0.0024900\n",
      "Step no. 29, convergence: 0.0022209\n",
      "Step no. 30, convergence: 0.0019379\n",
      "Step no. 31, convergence: 0.0016455\n",
      "Step no. 32, convergence: 0.0013615\n",
      "Step no. 33, convergence: 0.0011048\n",
      "Step no. 34, convergence: 0.0008858\n",
      "Step no. 35, convergence: 0.0009323\n",
      "Step no. 36, convergence: 0.0009848\n",
      "Step no. 37, convergence: 0.0011131\n",
      "Step no. 38, convergence: 0.0012254\n",
      "Step no. 39, convergence: 0.0012990\n",
      "Step no. 40, convergence: 0.0013194\n",
      "Step no. 41, convergence: 0.0012828\n",
      "Step no. 42, convergence: 0.0011975\n",
      "Step no. 43, convergence: 0.0011519\n",
      "Step no. 44, convergence: 0.0010939\n",
      "Step no. 45, convergence: 0.0010183\n",
      "Step no. 46, convergence: 0.0009343\n",
      "Step no. 47, convergence: 0.0008489\n",
      "Step no. 48, convergence: 0.0007661\n",
      "Step no. 49, convergence: 0.0006879\n",
      "Step no. 50, convergence: 0.0006392\n",
      "Step no. 51, convergence: 0.0006060\n",
      "Step no. 52, convergence: 0.0005716\n",
      "Step no. 53, convergence: 0.0005361\n",
      "Step no. 54, convergence: 0.0005002\n",
      "Step no. 55, convergence: 0.0004644\n",
      "Step no. 56, convergence: 0.0004292\n",
      "Step no. 57, convergence: 0.0003951\n",
      "Step no. 58, convergence: 0.0003727\n",
      "Step no. 59, convergence: 0.0003584\n",
      "Step no. 60, convergence: 0.0003410\n",
      "Step no. 61, convergence: 0.0003208\n",
      "Step no. 62, convergence: 0.0002978\n",
      "Step no. 63, convergence: 0.0002723\n",
      "Step no. 64, convergence: 0.0002450\n",
      "Step no. 65, convergence: 0.0002166\n",
      "Step no. 66, convergence: 0.0001980\n",
      "Step no. 67, convergence: 0.0001968\n",
      "Step no. 68, convergence: 0.0001925\n",
      "Step no. 69, convergence: 0.0001852\n",
      "Step no. 70, convergence: 0.0001753\n",
      "Step no. 71, convergence: 0.0001683\n",
      "Step no. 72, convergence: 0.0001651\n",
      "Step no. 73, convergence: 0.0001615\n",
      "Step no. 74, convergence: 0.0001577\n",
      "Step no. 75, convergence: 0.0001536\n",
      "Step no. 76, convergence: 0.0001493\n",
      "Step no. 77, convergence: 0.0001449\n",
      "Step no. 78, convergence: 0.0001404\n",
      "Step no. 79, convergence: 0.0001358\n",
      "Step no. 80, convergence: 0.0001311\n",
      "Step no. 81, convergence: 0.0001264\n",
      "Step no. 82, convergence: 0.0001217\n",
      "Step no. 83, convergence: 0.0001170\n",
      "Step no. 84, convergence: 0.0001123\n",
      "Step no. 85, convergence: 0.0001083\n",
      "Step no. 86, convergence: 0.0001096\n",
      "Step no. 87, convergence: 0.0001102\n",
      "Step no. 88, convergence: 0.0001103\n",
      "Step no. 89, convergence: 0.0001096\n",
      "Step no. 90, convergence: 0.0001083\n",
      "Step no. 91, convergence: 0.0001071\n",
      "Step no. 92, convergence: 0.0001071\n",
      "Step no. 93, convergence: 0.0001070\n",
      "Step no. 94, convergence: 0.0001068\n",
      "Step no. 95, convergence: 0.0001064\n",
      "Step no. 96, convergence: 0.0001058\n",
      "Step no. 97, convergence: 0.0001049\n",
      "Step no. 98, convergence: 0.0001038\n",
      "Step no. 99, convergence: 0.0001023\n",
      "Step no. 100, convergence: 0.0001005\n",
      "Step no. 101, convergence: 0.0000985\n",
      "Step no. 102, convergence: 0.0000961\n",
      "Step no. 103, convergence: 0.0000935\n",
      "Step no. 104, convergence: 0.0000907\n",
      "Step no. 105, convergence: 0.0000877\n",
      "Step no. 106, convergence: 0.0000845\n",
      "Step no. 107, convergence: 0.0000813\n",
      "Step no. 108, convergence: 0.0000781\n",
      "Step no. 109, convergence: 0.0000757\n",
      "Step no. 110, convergence: 0.0000755\n",
      "Step no. 111, convergence: 0.0000752\n",
      "Step no. 112, convergence: 0.0000749\n",
      "Step no. 113, convergence: 0.0000744\n",
      "Step no. 114, convergence: 0.0000737\n",
      "Step no. 115, convergence: 0.0000729\n",
      "Step no. 116, convergence: 0.0000719\n",
      "Step no. 117, convergence: 0.0000707\n",
      "Step no. 118, convergence: 0.0000694\n",
      "Step no. 119, convergence: 0.0000678\n",
      "Step no. 120, convergence: 0.0000661\n",
      "Step no. 121, convergence: 0.0000656\n",
      "Step no. 122, convergence: 0.0000657\n",
      "Step no. 123, convergence: 0.0000656\n",
      "Step no. 124, convergence: 0.0000654\n",
      "Step no. 125, convergence: 0.0000650\n",
      "Step no. 126, convergence: 0.0000645\n",
      "Step no. 127, convergence: 0.0000638\n",
      "Step no. 128, convergence: 0.0000631\n",
      "Step no. 129, convergence: 0.0000622\n",
      "Step no. 130, convergence: 0.0000611\n",
      "Step no. 131, convergence: 0.0000599\n",
      "Step no. 132, convergence: 0.0000586\n",
      "Step no. 133, convergence: 0.0000591\n",
      "Step no. 134, convergence: 0.0000606\n",
      "Step no. 135, convergence: 0.0000620\n",
      "Step no. 136, convergence: 0.0000634\n",
      "Step no. 137, convergence: 0.0000647\n",
      "Step no. 138, convergence: 0.0000660\n",
      "Step no. 139, convergence: 0.0000672\n",
      "Step no. 140, convergence: 0.0000684\n",
      "Step no. 141, convergence: 0.0000695\n",
      "Step no. 142, convergence: 0.0000706\n",
      "Step no. 143, convergence: 0.0000717\n",
      "Step no. 144, convergence: 0.0000728\n",
      "Step no. 145, convergence: 0.0000738\n",
      "Step no. 146, convergence: 0.0000749\n",
      "Step no. 147, convergence: 0.0000760\n",
      "Step no. 148, convergence: 0.0000771\n",
      "Step no. 149, convergence: 0.0000782\n",
      "Step no. 150, convergence: 0.0000794\n",
      "Step no. 151, convergence: 0.0000806\n",
      "Step no. 152, convergence: 0.0000817\n",
      "Step no. 153, convergence: 0.0000829\n",
      "Step no. 154, convergence: 0.0000840\n",
      "Step no. 155, convergence: 0.0000850\n",
      "Step no. 156, convergence: 0.0000859\n",
      "Step no. 157, convergence: 0.0000866\n",
      "Step no. 158, convergence: 0.0000872\n",
      "Step no. 159, convergence: 0.0000875\n",
      "Step no. 160, convergence: 0.0000876\n",
      "Step no. 161, convergence: 0.0000873\n",
      "Step no. 162, convergence: 0.0000867\n",
      "Step no. 163, convergence: 0.0000857\n",
      "Step no. 164, convergence: 0.0000842\n",
      "Step no. 165, convergence: 0.0000824\n",
      "Step no. 166, convergence: 0.0000802\n",
      "Step no. 167, convergence: 0.0000777\n",
      "Step no. 168, convergence: 0.0000749\n",
      "Step no. 169, convergence: 0.0000718\n",
      "Step no. 170, convergence: 0.0000685\n",
      "Step no. 171, convergence: 0.0000650\n",
      "Step no. 172, convergence: 0.0000615\n",
      "Step no. 173, convergence: 0.0000580\n",
      "Step no. 174, convergence: 0.0000544\n",
      "Step no. 175, convergence: 0.0000510\n",
      "Step no. 176, convergence: 0.0000477\n",
      "Step no. 177, convergence: 0.0000445\n",
      "Step no. 178, convergence: 0.0000415\n",
      "Step no. 179, convergence: 0.0000387\n",
      "Step no. 180, convergence: 0.0000360\n",
      "Step no. 181, convergence: 0.0000359\n",
      "Step no. 182, convergence: 0.0000363\n",
      "Step no. 183, convergence: 0.0000368\n",
      "Step no. 184, convergence: 0.0000372\n",
      "Step no. 185, convergence: 0.0000376\n",
      "Step no. 186, convergence: 0.0000380\n",
      "Step no. 187, convergence: 0.0000383\n",
      "Step no. 188, convergence: 0.0000386\n",
      "Step no. 189, convergence: 0.0000388\n",
      "Step no. 190, convergence: 0.0000390\n",
      "Step no. 191, convergence: 0.0000391\n",
      "Step no. 192, convergence: 0.0000392\n",
      "Step no. 193, convergence: 0.0000392\n",
      "Step no. 194, convergence: 0.0000391\n",
      "Step no. 195, convergence: 0.0000390\n",
      "Step no. 196, convergence: 0.0000388\n",
      "Step no. 197, convergence: 0.0000386\n",
      "Step no. 198, convergence: 0.0000383\n",
      "Step no. 199, convergence: 0.0000380\n",
      "Step no. 200, convergence: 0.0000376\n",
      "Step no. 201, convergence: 0.0000372\n",
      "Step no. 202, convergence: 0.0000367\n",
      "Step no. 203, convergence: 0.0000362\n",
      "Step no. 204, convergence: 0.0000356\n",
      "Step no. 205, convergence: 0.0000350\n",
      "Step no. 206, convergence: 0.0000344\n",
      "Step no. 207, convergence: 0.0000338\n",
      "Step no. 208, convergence: 0.0000331\n",
      "Step no. 209, convergence: 0.0000335\n",
      "Step no. 210, convergence: 0.0000345\n",
      "Step no. 211, convergence: 0.0000354\n",
      "Step no. 212, convergence: 0.0000364\n",
      "Step no. 213, convergence: 0.0000373\n",
      "Step no. 214, convergence: 0.0000381\n",
      "Step no. 215, convergence: 0.0000390\n",
      "Step no. 216, convergence: 0.0000397\n",
      "Step no. 217, convergence: 0.0000404\n",
      "Step no. 218, convergence: 0.0000411\n",
      "Step no. 219, convergence: 0.0000416\n",
      "Step no. 220, convergence: 0.0000421\n",
      "Step no. 221, convergence: 0.0000424\n",
      "Step no. 222, convergence: 0.0000427\n",
      "Step no. 223, convergence: 0.0000428\n",
      "Step no. 224, convergence: 0.0000428\n",
      "Step no. 225, convergence: 0.0000426\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step no. 226, convergence: 0.0000424\n",
      "Step no. 227, convergence: 0.0000420\n",
      "Step no. 228, convergence: 0.0000414\n",
      "Step no. 229, convergence: 0.0000408\n",
      "Step no. 230, convergence: 0.0000400\n",
      "Step no. 231, convergence: 0.0000391\n",
      "Step no. 232, convergence: 0.0000381\n",
      "Step no. 233, convergence: 0.0000371\n",
      "Step no. 234, convergence: 0.0000359\n",
      "Step no. 235, convergence: 0.0000347\n",
      "Step no. 236, convergence: 0.0000335\n",
      "Step no. 237, convergence: 0.0000322\n",
      "Step no. 238, convergence: 0.0000309\n",
      "Step no. 239, convergence: 0.0000295\n",
      "Step no. 240, convergence: 0.0000282\n",
      "Step no. 241, convergence: 0.0000269\n",
      "Step no. 242, convergence: 0.0000270\n",
      "Step no. 243, convergence: 0.0000273\n",
      "Step no. 244, convergence: 0.0000276\n",
      "Step no. 245, convergence: 0.0000278\n",
      "Step no. 246, convergence: 0.0000281\n",
      "Step no. 247, convergence: 0.0000284\n",
      "Step no. 248, convergence: 0.0000287\n",
      "Step no. 249, convergence: 0.0000290\n",
      "Step no. 250, convergence: 0.0000294\n",
      "Step no. 251, convergence: 0.0000297\n",
      "Step no. 252, convergence: 0.0000300\n",
      "Step no. 253, convergence: 0.0000302\n",
      "Step no. 254, convergence: 0.0000305\n",
      "Step no. 255, convergence: 0.0000308\n",
      "Step no. 256, convergence: 0.0000310\n",
      "Step no. 257, convergence: 0.0000312\n",
      "Step no. 258, convergence: 0.0000314\n",
      "Step no. 259, convergence: 0.0000315\n",
      "Step no. 260, convergence: 0.0000317\n",
      "Step no. 261, convergence: 0.0000317\n",
      "Step no. 262, convergence: 0.0000318\n",
      "Step no. 263, convergence: 0.0000318\n",
      "Step no. 264, convergence: 0.0000317\n",
      "Step no. 265, convergence: 0.0000316\n",
      "Step no. 266, convergence: 0.0000315\n",
      "Step no. 267, convergence: 0.0000313\n",
      "Step no. 268, convergence: 0.0000310\n",
      "Step no. 269, convergence: 0.0000307\n",
      "Step no. 270, convergence: 0.0000304\n",
      "Step no. 271, convergence: 0.0000300\n",
      "Step no. 272, convergence: 0.0000296\n",
      "Step no. 273, convergence: 0.0000291\n",
      "Step no. 274, convergence: 0.0000286\n",
      "Step no. 275, convergence: 0.0000284\n",
      "Step no. 276, convergence: 0.0000283\n",
      "Step no. 277, convergence: 0.0000282\n",
      "Step no. 278, convergence: 0.0000281\n",
      "Step no. 279, convergence: 0.0000279\n",
      "Step no. 280, convergence: 0.0000277\n",
      "Step no. 281, convergence: 0.0000274\n",
      "Step no. 282, convergence: 0.0000271\n",
      "Step no. 283, convergence: 0.0000267\n",
      "Step no. 284, convergence: 0.0000263\n",
      "Step no. 285, convergence: 0.0000259\n",
      "Step no. 286, convergence: 0.0000255\n",
      "Step no. 287, convergence: 0.0000251\n",
      "Initial convergence, fine-tuning...\n",
      "Step no. 288, convergence: 0.0000246\n",
      "Convergence after 288 steps\n",
      "\n",
      "Convergence criterium:  4.28256965224e-07\n",
      "Out shape is  (42, 56, 38, 256)\n"
     ]
    }
   ],
   "source": [
    "#get original ica\n",
    "mmix_orig = tedica(nc, dd, options.conv,  options.fixed_seed, cost=options.initcost, final_cost = options.finalcost)\n",
    "#get tsoc stuff\n",
    "tsoc, tsoc_mean, tsoc_dm = get_tsoc(catd, t2sG, tes, mask, combmode)\n",
    "# Precalculate a bunch of things to make getting kappa and rho faster\n",
    "tsoc_unmask = unmask(tsoc, mask)\n",
    "tsoc_dm_unmask = unmask(tsoc_dm, mask)\n",
    "tsoc_dm_unmask_for_gc = fmask(tsoc_dm_unmask, mask).transpose()\n",
    "catd_uncatted = uncat2echos(catd,Ne)\n",
    "mask_tile = np.tile(mask,(1,1,Ne))\n",
    "catd_uncatted_masked = fmask(catd_uncatted, mask_tile).transpose()\n",
    "#initialize results list\n",
    "res = []\n",
    "#get Kappas,Rhos for orig mmix\n",
    "rr = {}\n",
    "rr['mmix'] = mmix_orig\n",
    "rr['kappas'],rr['rhos']  = get_kappas_rhos(catd,catd_uncatted,catd_uncatted_masked, mmix_orig, mask, mask_tile,t2s, t2sG, tes,combmode, head, tsoc, tsoc_unmask, tsoc_mean, tsoc_dm, tsoc_dm_unmask,tsoc_dm_unmask_for_gc, fout=options.fout,reindex=True)\n",
    "rr['score'] = get_score(rr['kappas'],rr['rhos'])\n",
    "res.append(rr)\n",
    "res_df = pd.DataFrame(res)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Starting Outerloop 0\n",
      "0  "
     ]
    }
   ],
   "source": [
    "# Run a bunch of perturbations to try to find a better mixing matrix\n",
    "# \"betterness\" is defined as minmizing the output of the function get_score, defined above\n",
    "# This will try inner_loop_n perturbations, then pick the mixing matrix corresponding\n",
    "# to the best score seen so far and start perturbing that\n",
    "# outer_loop_n defines how many times the best mixing matrix will be reset\n",
    "# epsi determines the scale of the perturbation\n",
    "# something between 0.001 and 0.01 seems to work well\n",
    "outer_loop_n = 1\n",
    "inner_loop_n = 1\n",
    "epsi = 0.001\n",
    "\n",
    "for j in range(outer_loop_n):\n",
    "    print('\\n Starting Outerloop %d'%j)\n",
    "    for i in range(inner_loop_n):\n",
    "        res.append(run_perturb(np.random.randn(nc,nc)[np.triu_indices(nc)],0.001, res_df.loc[res_df.score == res_df.score.min(), ['mmix']].values[0][0], nc))\n",
    "        print(i, end = '  ')\n",
    "    res_df = pd.DataFrame(res)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f2b7bef9240>]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n0EVEQkIBXUQkJP4/jHBf7bPvE8gAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f2b7b0cf668>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# plot result\n",
    "tmp = res_df.loc[0, ['kappas','rhos']]\n",
    "kappas = tmp['kappas']\n",
    "rhos = tmp['rhos']\n",
    "plt.plot(kappas, rhos, 'o', alpha = 0.7)\n",
    "\n",
    "tmp = res_df.loc[res_df.score == res_df.score.min(), ['kappas','rhos']]\n",
    "kappas = tmp['kappas'].values[0]\n",
    "rhos = tmp['rhos'].values[0]\n",
    "plt.plot(kappas, rhos, 'o', alpha = 0.7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save resdf if you're happy with the results, otherwise, go back up and more perturbations\n",
    "res_df.to_pickle('./perturbation_results_%s.pickle.gz'%strftime(\"%Y-%m-%d_%H:%M:%S\", gmtime()))\n",
    "# an example of how to load save results\n",
    "#test_load = pd.read_pickle('./perturbation_results_2017-11-22_15:52:35.pickle.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out shape is  (42, 56, 38, 256)\n"
     ]
    }
   ],
   "source": [
    "# take our new best mmix and reenter the normal meica processing pipline\n",
    "mmix_orig = res_df.loc[res_df.score == res_df.score.min(), ['mmix']].values[0][0]\n",
    "seldict,comptable,betas,mmix = fitmodels_direct(catd,mmix_orig,mask,t2s,t2sG,tes,combmode,head, fout=options.fout,reindex=True)\n",
    "\n",
    "np.savetxt('meica_mix.1D',mmix)\n",
    "if 'GROUP0' in sys.argv:\n",
    "    group0_flag = True\n",
    "else: group0_flag = False\n",
    "acc,rej,midk,empty = selcomps(seldict,mmix,head, knobargs=options,group0_only=group0_flag,strict_mode=options.strict)\n",
    "\n",
    "if len(acc)==0:\n",
    "    print(\"\\n** WARNING! No BOLD components detected!!! Please check data and results!\\n\")\n",
    "\n",
    "writeresults(OCcatd, comptable, mmix, nt, acc, rej, midk, empty, head)\n",
    "gscontrol_mmix(mmix, acc, rej, midk, empty, head)\n",
    "if options.dne: writeresults_echoes(acc, rej, midk, head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T1gs.nii\t      csstepdata.txt\t mepca_mix.1D\t    t2sv.nii\r\n",
      "__clin.nii.gz\t      dn_ts_OC.nii\t midk_rejected.txt  t2svG.nii\r\n",
      "__clout.nii.gz\t      dn_ts_OC_T1c.nii\t midk_ts_OC.nii     ts_OC.nii\r\n",
      "accepted.txt\t      feats_OC2.nii\t pcastate.pklgz     tsoc_nogs.nii\r\n",
      "betas_OC.nii\t      glsig.1D\t\t rejected.txt\t    tsoc_orig.nii\r\n",
      "betas_hik_OC.nii      hik_ts_OC.nii\t s0v.nii\t    veins_l0.nii\r\n",
      "betas_hik_OC_T1c.nii  hik_ts_OC_T1c.nii  s0vG.nii\t    veins_l1.nii\r\n",
      "comp_table.txt\t      lowk_ts_OC.nii\t s0vs.nii\r\n",
      "comp_table_pca.txt    meica_mix.1D\t sphis_hik.nii\r\n",
      "csdata.txt\t      meica_mix_T1c.1D\t t2ss.nii\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graveyard\n",
    "\n",
    "code I'm not using any more that might be usefull later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import basinhopping\n",
    "def print_fun(x, f, accepted):\n",
    "    print(\"at minimum %.4f accepted %d\" % (f, int(accepted)))\n",
    "def get_score(Kappas, Rhos):\n",
    "    return(-1*(Kappas.sum() + np.abs(Kappas - Rhos).sum() + Rhos.sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-254-6f15f87c6057>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbasinhopping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_perturb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m130\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m130\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtriu_indices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m130\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprint_fun\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/envs/venv/lib/python3.6/site-packages/scipy/optimize/_basinhopping.py\u001b[0m in \u001b[0;36mbasinhopping\u001b[0;34m(func, x0, niter, T, stepsize, minimizer_kwargs, take_step, accept_test, callback, interval, disp, niter_success, seed)\u001b[0m\n\u001b[1;32m    633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m     bh = BasinHoppingRunner(x0, wrapped_minimizer, take_step_wrapped,\n\u001b[0;32m--> 635\u001b[0;31m                             accept_tests, disp=disp)\n\u001b[0m\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;31m# start main iteration loop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/venv/lib/python3.6/site-packages/scipy/optimize/_basinhopping.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x0, minimizer, step_taking, accept_tests, disp)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;31m# do initial minimization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m         \u001b[0mminres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mminimizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mminres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mminimization_failures\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/venv/lib/python3.6/site-packages/scipy/optimize/_basinhopping.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, x0)\u001b[0m\n\u001b[1;32m    280\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mminimizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 282\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mminimizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    283\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/venv/lib/python3.6/site-packages/scipy/optimize/_minimize.py\u001b[0m in \u001b[0;36mminimize\u001b[0;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[1;32m    479\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_minimize_cg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjac\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    480\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'bfgs'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 481\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_minimize_bfgs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjac\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    482\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'newton-cg'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    483\u001b[0m         return _minimize_newtoncg(fun, x0, args, jac, hess, hessp, callback,\n",
      "\u001b[0;32m/opt/conda/envs/venv/lib/python3.6/site-packages/scipy/optimize/optimize.py\u001b[0m in \u001b[0;36m_minimize_bfgs\u001b[0;34m(fun, x0, args, jac, callback, gtol, norm, eps, maxiter, disp, return_all, **unknown_options)\u001b[0m\n\u001b[1;32m    941\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    942\u001b[0m         \u001b[0mgrad_calls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmyfprime\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwrap_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfprime\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 943\u001b[0;31m     \u001b[0mgfk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmyfprime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    944\u001b[0m     \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    945\u001b[0m     \u001b[0mN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/venv/lib/python3.6/site-packages/scipy/optimize/optimize.py\u001b[0m in \u001b[0;36mfunction_wrapper\u001b[0;34m(*wrapper_args)\u001b[0m\n\u001b[1;32m    290\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfunction_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mwrapper_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m         \u001b[0mncalls\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 292\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapper_args\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mncalls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunction_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/venv/lib/python3.6/site-packages/scipy/optimize/optimize.py\u001b[0m in \u001b[0;36mapprox_fprime\u001b[0;34m(xk, f, epsilon, *args)\u001b[0m\n\u001b[1;32m    701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    702\u001b[0m     \"\"\"\n\u001b[0;32m--> 703\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_approx_fprime_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    704\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    705\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/venv/lib/python3.6/site-packages/scipy/optimize/optimize.py\u001b[0m in \u001b[0;36m_approx_fprime_helper\u001b[0;34m(xk, f, epsilon, args, f0)\u001b[0m\n\u001b[1;32m    641\u001b[0m         \u001b[0mei\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    642\u001b[0m         \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepsilon\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mei\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 643\u001b[0;31m         \u001b[0mgrad\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxk\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mf0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    644\u001b[0m         \u001b[0mei\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    645\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/venv/lib/python3.6/site-packages/scipy/optimize/optimize.py\u001b[0m in \u001b[0;36mfunction_wrapper\u001b[0;34m(*wrapper_args)\u001b[0m\n\u001b[1;32m    290\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfunction_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mwrapper_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m         \u001b[0mncalls\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 292\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapper_args\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mncalls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunction_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-251-a88e0fd6208f>\u001b[0m in \u001b[0;36mrun_perturb\u001b[0;34m(starting_triu)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mperturb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexpm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mskew_sym\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mmmix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmmix_orig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mperturb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mkappas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrhos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_kappas_rhos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcatd\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcatd_uncatted\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcatd_uncatted_masked\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmmix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask_tile\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mt2s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt2sG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcombmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhead\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtsoc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtsoc_unmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtsoc_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtsoc_dm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtsoc_dm_unmask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtsoc_dm_unmask_for_gc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mreindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mget_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkappas\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrhos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-224-1bfc3c945b53>\u001b[0m in \u001b[0;36mget_kappas_rhos\u001b[0;34m(catd, catd_uncatted, catd_uncatted_masked, mmix, mask, mask_tile, t2s, t2sG, tes, combmode, head, tsoc, tsoc_unmask, tsoc_mean, tsoc_dm, tsoc_dm_unmask, tsoc_dm_unmask_for_gc, fout, reindex, mmixN, full_sel)\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;31m#Compute PSC dataset - shouldn't have to refit data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;32mglobal\u001b[0m \u001b[0mtsoc_B\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0mtsoc_B\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_coeffs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtsoc_dm_unmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmmix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtsoc_dm_unmask_for_gc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m     \u001b[0mtsoc_Babs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtsoc_B\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mPSC\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtsoc_B\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mtsoc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-220-90a38709be75>\u001b[0m in \u001b[0;36mget_coeffs\u001b[0;34m(data, mask, X, mdata, add_const)\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mXones\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m     \u001b[0mtmpbetas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstsq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0madd_const\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0mtmpbetas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmpbetas\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/venv/lib/python3.6/site-packages/numpy/linalg/linalg.py\u001b[0m in \u001b[0;36mlstsq\u001b[0;34m(a, b, rcond)\u001b[0m\n\u001b[1;32m   1955\u001b[0m         \u001b[0mwork\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlwork\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1956\u001b[0m         results = lapack_routine(m, n, n_rhs, a, m, bstar, ldb, s, rcond,\n\u001b[0;32m-> 1957\u001b[0;31m                                  0, work, lwork, iwork, 0)\n\u001b[0m\u001b[1;32m   1958\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'info'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1959\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mLinAlgError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'SVD did not converge in Linear Least Squares'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "res = basinhopping(run_perturb,np.random.randn(130,130)[np.triu_indices(130)], disp = True, callback = print_fun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "%lprun -f get_kappas_rhos run_perturb(np.random.randn(130,130)[np.triu_indices(130)],0.001, res_df.loc[res_df.score == res_df.score.min(), ['mmix']].values[0][0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
